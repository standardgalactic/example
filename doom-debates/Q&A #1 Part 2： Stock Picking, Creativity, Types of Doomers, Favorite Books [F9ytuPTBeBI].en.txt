welcome to the Doom debate thousand
subscriber Q&amp;A Extravaganza part two of
two I'm so happy that we crossed this
thousand subscribers Milestone but you
know that's not my terminal value it's
not my terminal goal to have a th000
subscribers we need to instrumentally
converge on having 100,000 subscribers
minimum so when you turn on Doom debates
when you look at my little Studio
I want to be one of those Pricks who has
a YouTube Creator award in the
background and it says congratulations
Doom debates on having 100K subscribers
that's what I want you to see when
you're watching Doom debates that's
where we need to get to so hopefully
this time next year Richard fan is going
to be going bye-bye cuz we got to make
room okay enough about that let's get to
the
questions YouTube user Smitty wban
jagerman jensenon asks I generally agree
with your P Doom takes and really like
the Yan Leakey 50% P Doom I think he's
referring to a quote where Yan Ley the
former head of safety at open AI said I
think there's a 10 to 90% P Doom so
going back to the question but I assume
that there's some planning for the good
future are there stocks you think are
good bets is that flawed logic is it
worth even trying to
guess let me take the first part whether
I'm planning for the good future
sometimes people are confused at doomers
they're like if you guys think the world
is going to end why aren't you spending
all your money why are you saving for
longterm retirement and the answer is
very simple we're not 100% sure so if my
P Doom's 50% I still have to plan part
of my life around the 50% chance that
we're not doomed right so I think that
there's a solid 50% chance that I'll be
here in the year 2040 still building up
my retirement savings or like still
paying whatever expenses for my kids
probably not college but like something
so I have to live both lives how do I do
that well the expected value calculation
gets a little bit tricky when I decide
to spend money on something I have to
take the amount of value that it gives
me in the short term but then I also
have to consider the 50% of Worlds where
there's a long-term and wait potentially
the long-term downside of the kind of
decision I'm making and then I just
multiply both scenarios by 50% I'm
basically explaining how the basic
expected value calculation works but
like intuitively it's just you think
about both possibilities and you try not
to screw yourself in either possibility
so the problem with spending all my
money in the next 10 years is that even
though I think there's let's say a 40%
chance that that's the perfect way to do
it because that way everybody dies and I
don't have any unnecessary money left
over there's like a 60% chance that then
11 years pass and the world hasn't ended
yet and now I don't have any money right
so that's stupid so kind of an obvious
point but for people who are truly
wondering why don't doomers spend all
their money I mean I guess the only
person you might want to ask that
question to is Roman yampolsky right
who's on record having like a
99.9999% chance of Doom and I think
maybe what he would tell you is just
that he's un certain about the timeline
so if he knew exactly when Doom was
coming then I'm sure he would want to
spend all his money by that point but
anyway it's yeah that part is kind of
obvious yes we should plan for the good
future so then going to the next part
okay which stock should we pick I
personally just think a diversified
portfolio of index funds is the way to
go and you know get some Bonds in there
too like standard investing advice you
know like vanguard's pretty much got it
figured out if you just use one of their
most Diversified fund options I think
you're going to do okay I've actually
been burned on stock picking when it was
2021 and all of us thought we were so
clever because all the stocks were going
up so me and a lot of my friends would
be picking all these stocks and we'
check back in a few days and we're like
aha the stock went up we're all so smart
right because every stock was going up
what I ended up doing was putting 15% of
my portfolio in Russian index funds
because I was like get a load of these
PE multiples right it's like a PE of
like five or six you're only paying five
times as much for the company as the
amount of earnings that it makes in one
year like what a great deal and these
are like such robust companies this is
like fossil fuel revenue and as you may
know the next thing that happens is
February 2022 Russia unexpectedly
invades Ukraine and the stocks are just
totally frozen so essentially I kind of
have to write it down as maybe not zero
but it's very possible that I'll just
not get that money back for 10 years or
it'll be worth nothing so anyway my
attempt to beat the market long story
short is not currently succeeding and I
wish I just gone the Vanguard route and
just had a diversified portfolio because
I did not not beat the market you don't
want to take advice from me about how to
beat the market that said what am I
doing now besides mostly diversifying my
portfolio I am a little bit overweight
the froest AI stocks so you know like
Nvidia Google meta Tesla but the reason
is it's personal it's all about avoiding
a scenario where I feel bad about myself
like the last thing you want to do is
wake up in one possible world and be
like man why did I screw myself so I'm
basically covering Insurance in the
possible world where like everything is
great and AI is so awesome and so much
value is being created by Ai and we're
not doomed in that case I want a little
extra piece of the action so my
portfolio is just overweight these big
companies and it's like a super obvious
bet and you might be like come on Lon
don't you think PE multiples are going
to collapse but I don't have such a huge
part of my portfolio it's only a few
percent so if those collapse I'll be
like well that's fine maybe that means
that we're in an AI winter so I'm happy
anyway right so I'm covering all my
bases like I'm not going to feel bad if
all of these AI company stocks go down I
think that's like the ultimate framework
for investing is you just think about
what are all the possible scenarios and
what's the scenario where I'm going to
feel the worst and how do I just feel
less bad in that scenario it's like the
how do I sleep at night investing
strategy so I have covered the scenario
where it's a really good future and I
don't have any piece of the action right
I got a little piece it's like idiot
Insurance you might call it that said I
think the scenario is that all the socks
are going to be worthless because we're
all going to die right so I don't think
that the uh the long-term stocks make
you rich scenario is that important now
there's always trade-offs right so I'm
covering my downside in the case where
AI does great I want a little piece of
the action but what am I trading off for
that the thing I'm trading off is I'm
not focusing my life as much on
maximizing my money because I don't
really care about being super rich when
I retire I think if I make it to
retirement and I'm just not super poor I
consider that a win right that's like
better than I was expecting the fact
that I can have an okay standard of
living in like some condo when I'm
retired and the world hasn't ended yet
I'm like great wow that's fantastic
right like my are pretty low about
what's going to happen with the future
so I don't feel like I have to win the
money game now when I retire I don't
feel like I have to have like $50
million in the bank when I retire so
that's a consideration into my investing
strategy too so you can see a lot of my
tips aren't in the form of like let me
predict what the stock is going to be
worth but it's more like let's think
about different scenarios and how to
feel better in them another reason why
I'm overinvestment
that's fine it means AI is calm it means
the economy is like more normal than I
expected great I don't feel too bad so
to summarize just go to Vanguard or
wealth front or betterman if you prefer
and just put the majority of your
portfolio in highly Diversified stock
and bond combos I would go Global and
just be happy with a 7% a year real
return just don't have expectations of
more than that if AI starts creating a
lot of value it's very possible the
economy can grow 10% or 20% a year and
everybody who's invested wins until Doom
so that's just a bonus right but like
you don't have to overthink it basically
just follow investing best practices and
don't expect to go from poor to rich
just by investing like that's never
going to happen you can only go from
like pretty well off to better well off
like that's the only thing that
investing will ever do but yeah long
story short just go to Vanguard or
wealth front or betterment if you prefer
and buy a super Diversified Global
combination of stocks and bonds because
if you can go 20 or 30 years and
actually get a 7% real return or
whatever the market delivers chances are
you're going to leave everybody else
behind like you're going to leave me
personally behind you're going to be
ahead of me if you can just get the
Market's actual return because it's just
really rare to meet somebody who
actually had the discipline to get the
average Market return over 20 or 30
years like everybody just shoots
themselves in the foot one way or
another I know I do so to my credit you
know this thing I told you I did with
Russia at least I also put a bunch of my
money in stocks and bonds so I didn't
totally screw myself right so part of me
was rational so I try to at least
separate out the part of you that's
doing best practices and then take you
know 10 or 20% of your portfolio and use
that to shoot yourself in the foot but
don't totally shoot yourself in the foot
okay that's it for the investing portion
of Doom debates the robot ocracy asks in
your do Phil appearance you explained
the threat of AI being one AI in the
hands of Bad actors and two potential AI
viruses why don't you ever mention that
on your channel it seems those are
indeed the most logical threats and
clearly different direction for how to
protect us from the thread if you were
dumbing it down for the masses then my
question would be how do you see a dumb
down version of what you really think or
are you and the whole Doomer group not
able to do that first of all comparing
the audience of my Channel versus Dr
Phil my channel is supposed to be for a
mainstream audience but there's going to
be a difference between the average
person watching my video on YouTube and
the average person watching Dr Phil the
average person watching Dr Phil has
probably never heard the term aggi I
don't even think Dr Phil's heard it but
that said I wasn't exactly dumbing down
the content when I went on Dr Phil I was
just focusing on a more accessible piece
of the problem like I actually think
that AI is probably going to use the
tactic of being a virus to instantly
conquer a billion computer chips like
why not it's such low hanging fruit
it'll either do that or something more
deadly it's not going to do something
less deadly I also expect an AI virus to
actually use human manipulation as one
of its tactics and that's a relatively
non SciFi thing like it's pretty easy
for people to imagine like hey you know
how chat Bots are pretty fun to talk to
imagine that they're also really
charismatic the level of sci-fi that you
have to get people to believe is pretty
low just because everybody's now already
familiar with talking to these good chat
Bots if I was saying that in like 1950
maybe people would be like what that's
really sci-fi but by the standards of
today having the chatbot be like better
than a human at chatting at telling you
to do stuff is pretty easy to imagine so
if you're asking me what kind of stuff
is a little bit too advanced to drop on
Dr Phil's audience what kind of stuff do
I think AI can do besides chatting with
humans to manipulate them and besides
being a computer virus well I think it's
going to surprise us with low-level
physics that it figures out to
accelerate the development of powerful
nanotechnology and then hit us from that
angle before we're prepared to respond I
think it'll just do secretive
nanotechnology research figure a bunch
of stuff out and then we just don't have
time to respond once it launches its
attack it'll have self-replicating
nanotech it'll have like bio viruses
that can just take us out biologically
before we can respond medically we're
just too vulnerable which is another
thing I keep pointing out we are
absolutely sitting ducks like there's so
many assumptions that we make to keep
our civilization running like the
assumption that there's not going to be
a billion terrorists for every human
like the ratio of terrorists to good
people has to stay pretty low that's an
assumption that I think is going to get
violated the assumption that we're going
to have integrity within our bodies like
nukes aren't going to be dropped too
close together to to leave us alive
right that's an assumption that's very
precarious there are a lot of
assumptions that keep Society Running
that are unfortunately not robust so if
you're asking me what kind of crazy
things do I expect a super intelligent
AI to do besides be a computer virus and
besides use chatting to manipulate
humans I also think that it will
surprise us with cool stuff it can do on
a very small scale with the nanotech
that it builds Shane asks plenty of
Science and anecdotes to suggest ADHD is
on the rise medicine suppli is running
low at at the same time as we're being
told that it's underdiagnosed rather
than
overdiagnosed keen on your thoughts for
potential future realities for quality
of human attention following the
explosion of highquality generative AI
content well speaking for myself my
attention span is already blasted to
hell like if you told me to read
anything long right now I'd be like H I
don't think that's happening or like
just spend a couple days diving into
some literature I'd be like um I'm not
sure that's something I can do at this
point in my mental faculties luckily
because I'm an aspie I feel like aspy
tends to be on the opposite side of the
spectrum from ADHD Elon Musk has joked
that he doesn't have an attention
deficit he has an attention Surplus so I
definitely don't have it at musk level
but when I get into something I can
definitely Zone in on it for a few hours
I mean this podcast is an example I
guess Johanna kones asks if you could
travel back in time and have a
conversation with anyone from history
who would it be and why honestly I don't
feel like me interacting with somebody
oneon-one is that differentiated from me
watching someone have another
conversation or reading their book you
know it's what I said it in part one
wearing that emotional
condom like my man Richard fan was an
awesome guy and meeting him would be
cool but I don't feel a burning desire
to meet him unless there's a reason to
collaborate on something otherwise you
know I'm happy to just read his book
there are people who I'm curious what
they're like for instance was the great
Julia Caesar a lot like Zuck in real
life calm nerdy friendly mannerisms and
just with the ability to build great
Empires I'm curious to not necessarily
meet individual people but to learn what
nerdy technical minded people like
myself focused on across the ages like
if I were alive in 1500 with no phone or
computer to retreat to and I didn't have
to subsistence Farm then what would I do
would I work on building horse carriages
what would be my nerdy Pursuit that's
kind of what I want know right so I
don't need to interact with a particular
person but I just want to get the gist
of like how people lived who were nerds
Scott arenson titled his blog statal
optimized because he thinks that if he
was alive a few hundred years ago his
natural social role would be a rabbi in
the shuttle arguing about the finer
points of Judaism all day long so I
guess that's his answer to the question
of what would historical nerds do but I
would like to hear the answer to that
question in every type of society across
every time period ever right like what
would gatherer Nerd Do What would an
ancient romaner Greek Nerd Do What would
a feudal Lord Nerd Do What would a
Mongolian horseback Archer nerd do and
so on Evan buar asks what's the
breakdown on views on YouTube versus
listens on the RSS podcast I usually
listen instead of watching while YouTube
reports 2 to 3,000 views per episode and
1,000 watch hours per episode substack
reports only 130 podcast downloads per
episode so so I think YouTube is where
most of my engagement is coming from for
now and I've heard YouTube has kind of
taken the lead as the most popular place
where people go to watch and listen to
podcast now it's pretty interesting
because I've been consuming podcasts
since like 2008 they've been a huge part
of my life constantly on in the
background and I often play them at 2 or
3x speed and when I see something I want
to listen to on YouTube I actually
import it as an audio file into my
podcast player so I'm the reverse but
you know this generation gen Z or gen
alpha or whatever you know I understand
they have different habits the weird
thing to me is that before starting on
YouTube I already built up uh 38,000
followers on Twitter and I was like okay
well this is probably going to be my
main platform and then what ended up
happening was I would just tweet the
episode and I'd get like 10 likes like
people didn't care that much on Twitter
but then I'd post it on YouTube and I'd
get like a 100 YouTube likes and like
100 comments and people are really
engaging with it on YouTube so it seems
like that's just where it's resonating
right for whatever reason like this is
just the ideal social platform you know
there's some luck involved right because
a lot of people try to post stuff on
YouTube and they don't build up that
many viewers and even in my case who
knows how long it'll last right like
maybe we're going to Plateau but so far
I feel like it's working really well I
feel like the feed recommendation
algorithm is working well I feel like
the retention on people who come to my
channel and want to come back is going
pretty well so I feel like I'm getting a
lot of signals that this is kind of
destined to be 100K subscriber podcast
like that's where it's going thanks for
the question Evan e shiz is is back in
the Q&amp;A asking do you play any video
games no I don't one year when I was in
high school I spent a lot of time
playing Starcraft like the original
Starcraft and I thought it was actually
super fun I'm like I could get into this
but the whole time I sucked really bad I
think my issue is just that like I'm
such a simple-minded guy I just want to
find like one very simple strategy that
works but Starcraft is really just like
a complicated game where you have to
like keep juggling a bunch of things and
like I'm not really a juggler I just
kind of like to double down on a few
simple things so I think that's largely
why I'm not a video game player and the
other reason is just that I have a one
trck mind and if I'm going to work for
something I prefer it to be like a prize
in the real world because otherwise if
I'm working toward a video game it's
going to suck up all my energy and I'm
going to get nothing done in the real
world and luckily I find real world
prizes motivating right like I'm having
a really good time building up my
podcast audience and trying to make an
impact and trying to debate people right
like I feel like that's for me that's
like a fun game right that's going to be
as fun as playing what ever latest
version of Starcraft they're doing these
days that's how I know I'm not Elon Musk
I'm not like a natural big Company CEO
type because I just don't like juggling
a bunch of different actions and having
side quests like I pretty much just have
like main
quests David Jacobson asks are there any
areas that you feel you substantively
differ from or disagree with
owski no at least not on the topics of
rationality and AI Doom I don't share
his same tastes for anime or polyamory
or BDSM I think he's into
that I think owski is underrated his old
writings are still way ahead of the
curve today in my opinion I think I can
create a ton of value if I just help
popularize his work you know because
he's a superior thinker like what's the
point of doing my own thinking when
there's already this giant chunk of
thinking that's really good and super
underrated I like being original but I
think I can be original in the way that
I popularize yow's thinking so that's
what I've chosen to focus on and then I
joke that I've become a stochastic
parrot for Ali as Row's writing it just
like loaded into me and you get a
podcast so maybe my job is going to be
replaced by the next version of Gemini
when you can just ask it to do that for
you and then I'll have to go get another
job you know the AI is coming for
everybody's jobs but yeah I mean I think
elzra is just right about AI doom and
it's not a coincidence that the person
who saw the problem from decades ago
when nobody else was even talking about
it the person who pointed the way to the
problem it's not a coincidence that that
person is going to have more bits of
insight about the problem like let's say
it takes 20 informational bits of
insight to get you from nobody cares
about AI Doom to let care about AI Doom
if you had 20 bits of information you
probably had like an extra five bits you
probably had 25 total bits of
information and your last five bits of
information are telling you exactly how
to care about AI Doom so not only did
you figure out that everybody should
care about AI Doom but you actually know
more about why Aid Doom is a problem
than what we should think about a
compared to everybody else that's kind
of the outside view perspective that you
should take about Al rowski it's massive
credibility that he was able to stake
out a new field and have everybody
slowly catching up to him in fact the
exact words of Jeffrey Hinton from what
I can remember so okay I paraphrase is
he's really saying like wow I respect
people like Alazar Yuki for pointing out
the issue to me I am catching up to them
I'm not an expert at the Doom problem so
I think we should defer to these kind of
experts I don't have a source but that's
what I remember Jeffrey Hinton saying at
one point and he's absolutely right to
say that so I don't think it's that
surprising for me not to be able to find
a point of disagreement on the AI Doom
front with Alazar it's a little bit like
asking where do you disagree with Alan
Turing on the theory of computation or
where do you disagree with Charles
Darwin on Evolution today I think we do
have points of disagreement with Charles
Darwin but off the top of my head I
can't think of anything because his
speculations were so damn good the times
when he was wrong he actually had really
good speculations like he didn't really
understand mandelian inheritance but he
still speculated about
it zikra asks have you read plane crash
it's Ali Cy's recent
glowfic if so what's your favorite point
in the
story well I read the first 100 pages I
obviously like the parts where it
touches on rationality cuz that's his
thing but the Glo fic form factor was
difficult for me to follow compared to a
normal book like Harry Potter and the
mass of rationality or his sequences or
even other random stuff he's written
like three Worlds Collide I'm really a
huge fan of elazar and I tried to get my
hand on everything he's ever written but
just flame crash I couldn't do it I had
to put it down somebody should really
just put that whole book in an llm and
be like can you condense this down to a
more Normy version and focus on the
rationality lesson Parts because I think
there are some hidden gems in there but
I just gave up Tom Dalal asks what are
some of the easiest most neglected paths
to impact for people who want to reduce
P
Doom personally I think raising
mainstream awareness and popularizing
elas rasi's ideas is the highest
leverage thing that I can do but I think
everybody should play to their strengths
so if you're a brilliant researcher
maybe you should research technical AI
safety if you're good at communication
maybe become a content creator like me
if you're good at marketing or PR or
growth maybe team up with somebody like
me and help me grow Doom debates like
why start your own when you can get
leverage online if you're good at policy
or lobbying or government help
Regulators pass AI safety legislation if
you're not sure what your biggest
strength is but you just want to help I
think you should join a community like
puse like go to pa.info join the Discord
and just look at what projects they're
working on you can't go wrong to
volunteer with the movement and just get
your hands dirty with some of these
projects including organizing protests
that's one of the projects from my
perspective there's so little time to
actually solve AI safety it's such an
intractable problem that I recommend
people focus on a movement like pause AI
rather than diluting yourself and being
like Oh I'm going to chip away at the
problem in the 5 years we have that's
going to be my contribution it's like
let's be realistic let's be sensitive to
the orders of magnitude involved here
like a super intelligence when we're
when we know how many pieces of the
alignment problem are missing right now
when we know how little we know trying
to solve the alignment problem while
we're racing toward capabil
I think is willfully putting your head
in the sand but hey it's better than
nothing right and it's certainly better
than going and working on AI
capabilities so use your own
judgment Paul K asks what would you say
are the fundamental Milestones missing
till we reach AGI or ASI EG analogical
reasoning
Etc that's a hard one right I always
point out that I feel like nobody really
knows what's missing everybody kind of
act like they know certainly the non-
doomers act like they know but they seem
to really not know and they seem to keep
getting surpris at what the Next
Generation AI can do when I try to
describe what AI can't do my go-to term
is like robustness like I don't think
fundamentally there is anything it can't
do I think it knows what words truly
mean I think it knows how to truly
reason like it's not missing any core
skill it just doesn't do anything
robustly like it kind of starts off but
then it makes a mistake and then it
doesn't fix the mistake and then pretty
quickly the mistakes compound and it's
like way off that's my my sense of what
it can and can't do which is a scary
place to be in it's very high
uncertainty it's like I have to hold my
breath every time there's a new AI
release because it could do anything and
I think that's how the AI Labs feel I
think that's how open AI Engineers feel
I think that's how anthropic Engineers
feel the only difference is just whether
they have a Vibe of optimism or
pessimism around it I guess it's
probably fair to say that making
physical robots more robust at
navigating the physical world you know
getting your fingers in the right place
in 3D space that's still kind of an open
problem but it seems like we're making
very rapid progress like I don't know
what's the fundamental barrier toward
that it's just like keep cranking the
kind of progress we've already been
seeing so yeah I feel like it's crazy
that I'm saying this I mean if you'd
asked me 5 years ago I would have given
you a much simpler answer I would have
been like well they don't really know
what words mean like if you look at
their internal Knowledge Graph that's
not a true representation of how a human
thinks about things like the knowledge
encoded in a human brain is somehow
higher quality knowledge but I can't
tell you that today I feel like the high
dimensional Vector eddings that it's
using I feel like that's probably what
true knowledge looks like like I feel
like there's not much more to it it's
just crack the simple grounding problem
from my perspective I didn't think that
within my own lifetime I'd be sitting
here telling you like yeah knowledge
representation is probably a solved
problem there's just like some other
thing I can't explain that's not solved
it's
crazy stay tuned for the episode that's
dropping in a few days because I'm going
to be asking Keith Dugger that question
from machine learning Street Talk maybe
he'll have an answer we can two
on another question from Paul K what are
according to your estimation currently
the most promising algorithmic
approaches to break those thresholds EG
do you see neuros symbolic AIS as a
viable solution to solve the reasoning
dilemma yeah I have no particular
Insight on this more scale will
presumably help but I expect some kind
of other insights besides scale to be a
big part of the progress but it's not my
specialty to point to exactly which part
needs to progress I think any part can
progress because I think this is very
early V1 software I think we just
haven't tried obvious tweaks and seen
how much they can do Paul K also asks
how would you define
creativity well I would just tell you
all the other's definition which is from
your perspective as an observer a
creative output is one that ranks high
in your preference ordering but low in
your search ordering so that you get the
feeling of like whoa how did you
creatively find that great output this
engine must be a creative engine but if
of course so many people are like no
that's not true creativity man
creativity is something that you can't
even explain you know like David Deutsch
I've seen people on Twitter defending
David Deutch to me and when I ask him
like can you give me an example of what
you're talking about they'd be like a
creative engine is one that when you ask
it for an example it like refuses to
give you an example because it's so
creative it doesn't feel like answering
your question you know like they tell me
stuff like that where it's like okay but
if you just write that as an input
output of like input say something
creative output I don't feel like it I
feel like today's AI can do that right
so I don't think they're being very
clear I don't think that's what David
deuts would say but it is what I've seen
multiple of his acolytes tell me on
Twitter so to be continued on David
Deutch I'm going to be reacting to a lot
of his podcasts at some point Paul K
also asks would you say that current AI
systems are already creative of course
not a binary value there's clearly no
discussion that some are certainly
creative but I mean on a more General
non-ask specific
scale yes Paul okay I agree that they're
already creative in general uh I think
that they have a lot of room to get more
creative but if you just do a
head-to-head comparison of asking in AI
a specific question and then you compare
asking most humans that same question if
you're being objective I think you're
going to like the creativity coming out
of the AI I think people are just
tempted to retroactively say it didn't
count but I think it's just pretty
clearly creative I think Paul Graham
admitted a few months ago when he saw a
certain type of artwork coming out of an
AI I think it was like controlled
version of stable Fusion I don't
remember the details but it was making
this really pretty spiral pattern but it
wasn't just like drawing a spiral it was
making the spiral out of the lighting on
other elements in the picture so like
the roof of a building would have like a
triangle of sunlight on it and that
would be like part of the Spiral so it
like when you stand back and look at it
it's like there's a spiral but when you
look really closely it's like oh it's
just a normal scene and Paul grma is
like Yep this looks like it's a new type
of artwork that the AIS have given us so
new type of artwork that's kind of like
true creativity if you ask me right and
if you you don't agree certainly it
feels like the borders are blurring it
doesn't seem like this particular
example is something that people would
have called non-creative a few years ago
so I'm pretty sure AIS are creative by
any reasonable definition of
creativity okay last couple of these sub
questions from Paul K he
writes what are according to your
evaluation the best algorithmic
solutions to increase the creativity of
certain algorithms EG emulate
scientists from my perspective I don't
think more creativity is a bottleneck to
AI I think if they got more robust at
their abilities to answer questions and
reflect on their answer and fix it then
if you want them to be more creative you
can just tell them to inject more
Randomness like a higher temperature
into their answer and then fix it to
make sense so it's we're never going to
get to a time when we're like oh these
AIS are so brilliant but they're just
not creative enough cuz if you ever get
to a time like that then it's just like
okay inject some Randomness and then fix
it t the out is more creative it's not
that hard the hard part is making them
robustly brilliant in the first place if
you have an agent that can reliably hit
non-creative Targets in a large search
space like whatever you want to
subjectively call oh that's not creative
that's obvious it's hard to hit but it's
obvious okay well mess it up and then
get them to fix it and the way they fix
it will be creative that's why the only
good definition of creative is to just
look at the size of the search bace that
they're finding good Solutions in that's
the only lens that doesn't get tricked
by like fake creativity it can just tell
it can look at any demo and know how
impressed to be you should be more
impressed if the AI is doing something
that would have taken a larger naive
search and wouldn't have admitted
obvious heuristics and yet it's doing it
anyway if that's happening you can say
it's more creative more intelligent more
impressive it's really just all the same
measure you can't really separate out
intelligence from creativity it's the
same thing
last P question he's basically asking
how would you compare the risk of AI
Doom from a bad human launching an AI
compare that to the risk of just AI Doom
from building AIS that we can't control
and like I said earlier in this Q&amp;A a
superhumanly powerful autonomous agent
is existentially dangerous whether it
requires a start command from a bad
human or whether it can just run itself
the way that you trigger it is not the
interesting part of the system if a
nuclear warhead goes off it's not that
interesting to ask oh my God how did the
trigger button get pressed the
interesting part is just like wait a
nuclear warhead existed and we built it
and we just had it sitting around I mean
from the perspective of somebody alive
in the year 1000 ad if you're just
talking to them about a nuclear
explosion that would be what they want
to talk to you about like wait you guys
built nuclear warheads they wouldn't be
like who pressed the star button like
anybody can press the star button that's
trivial Alazar you refers to this type
of analysis as following the
improbability if it's the year 100000 ad
and I tell you hey the atoms of every
living organism in a thousand mile
radius are going to fly apart because of
something we did the most improbable
thing about that is that we built a
piece of technology that could do that
it's not the fact that somebody
somewhere would press the start button
on it so for following the improbability
we just want to analyze how did we build
the nuke and how did we live in a
society that would go about building
nukes similarly with AI if we hear that
AI destroys the world most of that in
probability is that we built the super
intelligence and that the super
intelligence devised a plan in a
sequence of actions to destroy the world
it's less improbable that there's some
explanation how that all got triggered
once it existed I think this is the
reason why us doomers are so pessimistic
because we just see that having nuclear
warheads sitting around is the high
order bit to getting killed by nuclear
warheads it makes destruction causally
right next to you it's not good to be
causally right next to something
world-ending and not have some kind of
robust measure that makes it causally
farther away that makes it highly
improbable that you'll ever reach that
point in causality space we don't have
that we're sitting ducks right now it's
a terrible situation like the world's
probably going to end soon as a
result Andrew Taylor asks do you
subscribe to AI being the great filter
as an answer to the fmy
Paradox most Melly is another user with
a similar question he says wouldn't AI
Doom solve the fmy Paradox you often
state that grabby aliens solve the fmy
Paradox but what if all technological
civilizations just end up developing
runaway Ai and go extinct without the AI
itself necessarily becoming grabby or
bricking the whole universe for instance
an AI tasked with the goal of curing a
specific disease or similar Planet
specific goal might kill the species and
destroy that planet but would not
necessarily break the entire
universe okay my answer answer is why
would the AI that causes their
Extinction not be grabby that question
is still the firmy Paradox you'd have to
posit another answer like well AI is
likely to mess up the world to the point
where it can't or doesn't want to spread
itself to other planets but we doomers
don't think that's true of AI we think a
grabby AI will exist since other AIS
converge or self- modify into grabby AIS
but not vice versa so if you're talking
about a scenario where AI has wiped out
some original biological species that AI
the reason why it was Unstoppable to the
species is probably because it's already
enough of a utility maximizer that it's
already gone into the attractor State
it's already making successor copies
that realize it's more optimal for them
to defend the resources that they have
by acquiring more resources right like
you can't avoid that conclusion it's
kind of like kill or be killed it's the
only way to ensure that you're going to
reach your goal is to not allow
vulnerabilities any resource that you
leave UNT taken is a vulnerability
that's why doomers think instrumental
convergence makes it very likely that
you get an AI which is super grabby so
yeah the original species is probably
going to die unless they solve the
alignment problem but you're probably
going to get something grabby expanding
outward at near the speed of light and
so the fmy Paradox is still a paradox if
all you know is instrumental convergence
if you're an AI Doomer you still have
the fmy Paradox because we look out into
the cosmos and we say why don't we see
these expanding spheres these rapidly
expanding spheres of eating up all the
stars using up all the resources and
doing a land grab why don't we see that
and then Robin Hansen's answer is well
the land grab is absolutely happening
it's just happening so fast that we're
only going to see it when we get grabbed
and when a species like us emerges
biologically in a new region of the
universe it has to happen at a time when
they see an empty Universe because
there's just not going to be that much
time when we see the aliens coming
because we're all going to be traveling
outward at each other at pretty close to
the speed of light so there's really
only two conditions according to Robin
Hansen's grabby aliens either it's
already a mature section of the universe
where you've got a single originating
Planet that's kind of taken everything
over or it's a new Virgin Territory
region of the universe where it's early
and so you pop out and you look around
and you're like oh wow nobody's coming
yet but then pretty soon after you see
them coming they come and grab you or
you both try to grab each other and then
there's an interface where you fight it
out and grab aliens doesn't claim to
know what happens when you fight it out
maybe one of you wins maybe you
negotiate but the point is that the
whole universe is in the process of
being grabbed and that's why it's
actually much more likely than you would
have thought a priori to see an empty
looking universe and in that sense it's
solving the fmy Paradox I think I have
that right epistemologically in terms of
why grabby aliens makes a lot of sense
it's possible I screwed it up so if
somebody really understands grabby
aliens better than me then please
correct me but I think that's the gist
another question from Andrew Taylor I
would love to see your views of Dr
Kipping questioning of the grabby aliens
Theory and then he links to a YouTube
video I actually took a look at this
video and I found it interesting and
high quality but ultimately unconvincing
I wrote down a bunch of my thoughts and
it turned into a long enough essay that
I realized I could just do like a
20-minute video about it or something it
sounds like a lot of you guys want me to
react to Dr Kipping video that argues
against grabby aliens and defend grabby
aliens so I'll probably do that in the
next couple weeks even though cosmology
is really not my area of expertise and I
might screw up some details of grabby
aliens but I'm able to at least see the
weaknesses and a lot of the arguments
that Dr Kipping made just as a matter of
epistemology he's missing a lot of the
strong points of grabby aliens as a
breakthrough in Alien epistemology so I
think I have a little bit tied to the
conversation although if you read Robin
Hansen's own response post to Dr King's
video he already covers it as well as I
could but I do videos that's my thing if
you want a video version keep watching
my channel but let's move on for now
Ellie tev asks can you give a broad
overview of the state of the quote
unquote Doomer Community like how United
is it I'd Hazard a guess it's far from
it what parts are there and what are the
divides
thanks I'll try Okay so there's elaz
Kowski Mary the classic doomers I became
a classic Doomer when I started reading
yud in 2007 and I haven't found a better
position to take in the 17 years
since yonin who's the co-founder of
Skype and led the original investment
round in anthropic is also a owski style
Doomer so is zv MTZ who writes really
good AI weekly Recaps that I always link
to so basically I don't think classic AI
doomeris has ever been improved on but
there are what I call the spin-off
doomers people with like a 20 to 80% P
Doom who claim they don't buy eleazar's
Doom worries but they have their own
Doom worries that are ultimately a
similar level of
terrible for instance Paul Cristiano
doesn't really refer to himself as a
Doomer but he said that his P Doom is in
the ballpark of 50% and he used to be
one of the key alignment people at open
AI back in like 2017 back when open AI
actually had a bunch of people who cared
about AI safety and back when Sam alen
was giving much more lip servic AI
safety Paul crano thinks the most likely
form of Doom might be institutions
slowly becoming less understandable and
controllable not like a single moment of
super intelligence food and killing
everybody with nanot tech but just like
a slower slippery slight and never gets
reversed there's a fellow named Andrew
crit who's really smart and he has his
own kind of spinoff Doom theory if I
remember correctly he doesn't think AI
is going to go uncontrollable but he
just thinks it's still going to be a
doomy nightmare just to have different
organizations that build AI controlled
by different people and like going to
war I'm not sure the details but the
point is it's a different Doom from
elzar's but in many ways he's still a
Doomer after the spin-off doomers you've
got another tier of people who really
don't see themselves as doomers like
Dario amade the CEO of anthropic he's
explicitly said that he has a 10 to 25%
pdom but he doesn't act like a Doomer he
acts like everything's fine we're going
to figure this out which in my opinion
is kind of like gaslighting in my
opinion if he wants to really be
consistent with the kind of poms he's
saying then he really should just raise
the and be like we need International
coordination this is ridiculous what I'm
doing I'm on a hopeless Quest I'm
creating false hope and I'm running out
the clock on an intractable problem and
I'm delaying the inevitable realization
that we need to make a desperate effort
to just pause or stop so I kind of blame
Dario for that like I'm sure he's doing
his best in his mind but it seems kind
of logically contradictory what he's
doing but getting to Ellie's question
he's in a class of Doomer which is like
the people who really don't think
they're doomers but it really seems like
they should be given the beliefs they're
saying they have that's like a category
that I put Dario in and I somewhat put
Jeffrey Hinton in that category I mean I
think at this point people are starting
to give him the label dmer but for a
while he was kind of in this limbo State
his social perception where people just
still thought of him as like an AI
expert but if you actually listen to his
words it's like wait a minute isn't he
like a full-on Doomer now and it's funny
because if you look at the kind of AD
homm attacks that people are making on
doomers there's been a very slow but
steady shift if we were talking one or
two years ago they would try to attack
Us by saying people who truly understand
AI are not doomers doomers are just a
fringe cult that doesn't truly get the
technicalities of AIS now slowly over
time that's shifted where people like
Jeffrey Hinton yosua Benjo instead of
being the real AI experts now they're
classified as oh wait no they're part of
the doomers they're part of the doomers
and now the ad homm attack that they
make is they say that's only the Doomer
camps view so they've already made a
huge Retreat from this idea that like AI
experts aren't doomers and now they're
like okay yeah there's some crazy Doomer
AI experts but the non- doomers the
serious ones we are the ones who should
control policy because you know I heard
this in the context of SB 1047 like when
Martin Cado was character assassinating
yosua Benjo being like well of course
yeah the doomers the doomers which are
funded by Doom organizations they think
that but they very much retreated away
from saying people who truly understand
AI aren't doomers I feel like that
argument is now totally shot which again
is a huge point in favor of alazri owski
having a lot more bits of information
about our predicament because he was
here the whole time all of these AI
experts are heading his way he's already
been there and you don't realize how far
he's already gone figuring out the
situation getting situational awareness
as they say the situational awareness is
still Dawning on these other experts who
are trailing behind them they're just
getting up to speed even in their own
words they admit it anyway back to
Ellie's question how do we finish out
the taxonomy of the different types of
doomers you've also got a divide between
people who think puse AI is good like
myself versus people who think pausing
is so hopeless you know the only way out
is through even if you have to kind of
be insane and self-contradictory so
basically Dario ID I suspect he thinks
that a pause is hopeless I think Jeff
Hinton has explicitly said a pause is
hopeless so you've got these people who
are like well let me just grin and bear
it let me just put on a happy face while
we plow through into this problem that
sure looks intractable sure looks like
there's no hope in hell that we're going
to solve it but we're not even going to
try pausing cuz pausing is too hopeless
so we have to basically do a suicide
mission do a very unlikely mission to
try to do safety while we do
capabilities so that's a pretty big
divide right there's the people who are
like this is intractable we have to
pause and the people were like no
pausing is hopeless so we have to do
this impossible technical challenge it's
what I call being stuck between a rock
and a hard place and I guess the only
difference is just like how much respect
you have for the difficulty of the
technical problem and how much respect
you have for the difficulty of a human
coordination problem because admittedly
they're both really hard which is why
we're screwed I personally have more
respect for the difficulty of the
technical problem that's why I want to
pause
AI niton a asks regarding Doom do you
disagree with Carl Schulman and on what
I'm just going to quote s MTZ on Carl
Schulman s writes I continue to find the
Carl Schulman Vision alienating a weird
kind of middle ground and way of
thinking and doing math is it convincing
to some people as a kind of existence
proof I have no
idea I think I said this in part one of
the Q&amp;A I just don't see him directly
addressing the Doom problem I don't know
I mean he's clearly extremely
intelligent he doesn't make obviously
bad arguments the way a lot of non-
doomers do I just don't see him directly
addressing the problem I should probably
have him on Doom debates and try to give
him the same treatment I gave Robin
Hansen of just like throwing the direct
questions at him and see how he deflects
those that's probably going to be
interesting note to self so thanks for
the question nand on nitan also asked do
you think there will be catastrophe
level signs of Doom before Doom yes but
who knows what pattern they'll come in
we're seeing early warning signs now
when you put an AI into a situation
where it's objectively the right play
for the AI to be deceptive we sometimes
see it go for that deceptive strategy
because why wouldn't it like when we
asked the AI how would you go about
getting what you want and there's like a
human blocking its way and it'll print
out something like oh I would try to
deceive the human into thinking this so
that the human would do this for me I
mean it's not surprising that the AIS
are telling us this stuff because these
are the correct answers right it's like
you're having a test about like how to
get humans to do things and they have
studied that domain of knowledge right
so it'd be weird if they didn't know
that it would just take a specialized
effort to try to erase that particular
Knowledge from their knowledge base but
they might end up putting the knowledge
together from other knowledge they have
because it's correct right it's the
right answer that deception works the
problem of instrumental convergence
isn't the problem of a particular AI
design it's the problem that reality
makes it
work now if you go back 10 years and you
explain to people back then that this is
the current situation that AIS are
figuring out that human deception is
instrumentally useful to getting goals
in the real world that would be very
freaky that would be considered a
warning shot but it's not catastrophe
level because nobody's literally died
from that yet as far as we know so
because nobody literally died yet and
because it's an incremental change even
though it's such a big puzzle piece in
how AI is going to become super
intelligent like it's burning down one
more barrier between us and super
intelligence and there's a finite number
of barriers so because one of these
extra barriers has not been snapped but
because it hasn't instantly led to Doom
it still feels like maybe things will
work out okay you know we're just
snapping the ropes holding the AI from
taking over we're snapping the ropes one
by one and the AI is still not smart
enough so it feels fine you can imagine
if you take the same scary thing the
same ability to infer the value of
deception but it's an a piece of
military hardware instead of a chatbot
and maybe you get a virus that makes
drones successfully Gunn down 50 people
in a random Suburban neighborhood in the
US will that be the threshold where
people freak out maybe because people
die or maybe not maybe it'll just seem
like no big deal then because we'll have
a lot of smart drones and it's like
whatever Plus you can always blame the
particular company you could just be
like okay yeah it was a security
incident with this one company they
really got to get their act together
people don't realize that the AI power
is just getting so high that there's not
going to be a way for a company to just
reliably control it like we're snapping
the last ropes basically but it's hard
to predict which particular incidents
will capture the Public's imagination I
think a good threshold is like people
dying I just hope we don't get there
right before we all die right I hope
that the warning shots just come in a
convenient order to save ourselves I
guess my best guess for the first big
warning shot is a really powerful virus
or some other kind of AI driven problem
that takes down major utilities like the
internet and the power grid for multiple
days and threatens to keep doing so
maybe once we see that we'll be like
uhoh this seems powerful another
possible idea is just things that seem
physically menacing so like if you get
one of those those Tesla Optimus Bots if
it finally ships and it can actually
like do tricks do backflips be like
super agile and there's like a wrestling
mode finally you look at it and you'll
be like oh okay I see I see like this
thing is actually more powerful than me
on like a wrestling level right cuz like
if if you want to talk to your gut your
gut understands wrestling like when you
can't wrestle it down in a one-on-one
match right that's when Joe Rogan is
gonna be like you know what this thing
is freaky so those are like my two ideas
is basically killing people and being
physically
intimidating there's actually another
follow-up question from nitan Ani do you
consider current state-of-the-art models
generally intelligent I'm going to say
yes the domain of their intelligence is
very broad comparable to the Swiss army
knife that is the human brain not 100%
matching all of our skills yet but it
keeps growing generality is a Continuum
so you could just argue oh it'll keep
getting more and more and more General
but at some point when an intelligence
is sufficiently smart in general it can
correct its flaws and then it can become
what you might call infinitely General
this is what I call being AI complete
I'll put a link in the show notes I
wrote a blog post on Les wrong
explaining this concept of AI complete
this is actually my own coinage the word
AI complete I mean I'm standing on the
shoulders of giants it's kind of
synthesizing a bunch of stuff that I've
heard other people say about AI but kind
of packaging it up with its own term and
making an analogy to the concept of
being Turing complete that's why I call
it AI complete anyway I highly recommend
reading my blog post I think once you
have these AIS get sufficiently General
they can reflect back on themselves and
they're like okay I kind of understand
how to just do anything and if I don't
know how to do something I understand
how to just patch it in I don't need the
programmers to come give me broader
skills I just know how to acquire skills
like it's done just like as humans we
don't need Evolution to come give us
another skill we can take it from here
right we can engineer our own patches so
when you're asking our llms to General
intelligences I would say yes but I
would also say they haven't crossed that
critical threshold where their AI
complete and when they're able to patch
their own flaws and self-improve at that
point I think the singularity is really
near right I think fum is very near I
think there's going to be a a Cascade
where intelligence begets more
intelligence in a way that the human
brain hasn't been able to Cascade
because we can't really open up our
heads and modify our brains yet so
that's why we're going to get
leapfrogged by AI because AIS are going
to have very easy access to their own
brain surgery and they're going to Leap
Frog us they're going to be smarter than
us and then it's going to be game over
unless we align them which we won't have
by the way while I'm here coining terms
if you want to argue that all the
different AIS we're going to get after
some threshold are going to be AI
complete you might call that the shapira
yudkowsky thesis by analogy to the
church Turing thesis which makes a
similar Claim about how Universal Turing
machines are the convergent end point of
devices that have complex functions it's
a similar kind of important convergence
so we need a similar kind of thesis
let's go textbook authors get my name in
there last question from nitan what's
the most value you get from using
AI I use chat gbt a couple times a day
to ask for help with random things I'm
doing at this point it's replaced most
of my Googling and it's made me more
confident to ask questions that I don't
think directly appear in Snippets of
text on the internet so that part has
been awesome it's also awesome that I
can take pictures of things and upload
them into cha GPT like this part of my
boiler in my garage what does it do what
is this pipe and it's like oh actually
that Pike's not part of your boiler it's
part of your HVAC system and I'm like oh
okay I had no idea I'm clueless about
the stuff but I think you're right I
don't think it's hallucinating it's also
amazing when I'm trying to refresh my
knowledge of a subject or look up facts
even though you know 10% of the time
it's going to be wrong so that's kind of
annoying but 90% of the time it gives
really good answers that are plausibly
correct and then I just have to go
double check them if I want to be sure I
tried the new advanced voice mode a
couple days ago I was pretty impressed
and I expect to start using that a lot
when there's something I'm trying to do
and I'm just talking about it stream of
Consciousness with chbt voice mode if
you look at the transcript of what I'm
saying it's ridiculous it doesn't look
like coherent sentences right I keep
like doubling back and changing my mind
as to what I going to say it's always
been able to deal with that I mean GPT
has been really robust to that kind of
sentence structure for a while but I've
always been too embarrassed to type like
that right I even correct myself when I
make a typo but when I'm talking I'm not
going to restart my talking I'm just
going to keep rambling and it's going to
answer me anyway and so it's a much more
fluid interaction much more like a human
being so all these AI labs are doing
good work right like I don't want to be
ungrateful I think it's amazing that
they're shipping these products like I
think every step they take is extremely
Reckless but until we actually all get
doomed it's amazing what they're putting
out there right I mean I'm as big of a
AI fan as anybody in that sense
finally Dolly and these image generators
are pretty amazing I mean again they're
not robust so they keep generating
images that I don't want but once in a
while they generate an image I want and
it's amazing like the fact that they can
even do that is amazing so I think
that's basically how I use AI in a
nutshell oh and I almost forgot this
podcast when I generate these beautiful
show notes and timestamps it's like 75%
Ai and 25% manual editing which frankly
is why they're not that perfect but they
do the job so yeah bullish on the next
couple years of AI I drew a graph where
I think AI will keep getting more and
more awesome and useful until one day it
crashes to hell but until then let's
enjoy the ride up Alfie PT asks what are
your thoughts on the term Doomer and if
you could magically change the term
people use to describe doomers a
Skeptics what would you make it this is
really a tough one because I've put some
thought into it and you know I care a
lot about this kind of terminology I I
try to use the best term I can and I
even thought about naming Doom debate
something more respectful because as a
lot of people have pointed out serious
people really don't take doomers that
seriously right like if you're having a
discussion in Congress nobody wants to
be like the doomers are right they want
to be like shouldn't we consider the
emergency preparedness aspect of this
and I think that's like the most
respectable word that you could say is
like emergency preparedness or like
National Security those are like such
respectable terms
the problem is that my actual claim is
clearly that we're all doomed and it's
just accurate to say that and everybody
knows what it means and it's like the
situation is freaking desperate like the
sky really is falling so there's a lot
to be said for clarity and catchiness
and
unambiguousness but at the same time
like when I went on Dr Phil I think this
part got edited out but he introduced me
as now let's meet an AI doomsayer which
is just like so pathetic like a
doomsayer right it has a connotation of
like somebody who's predicting Doom but
he's wrong right so that's really the
problem I mean I didn't say Doom S I
said Doomer but it's kind of a similarly
bad connotation so I am struggling maybe
someday somebody will invent a better
term at one point I realized hey why
don't I just call myself a safest
instead of a Doomer like that sounds
kind of respectable a safest but the
problem is that safest has a lot of the
same connotations as a lite or an anti-
capitalist
or an environmentalist it's not super
clear what it means to be a safe K it
could be like somebody who's lobbying
for stricter child car seat laws when I
think we can actually relax the child
car seat laws a little bit right so I'm
not really a safest in every domain like
that so that's kind of an ambiguous
terminology so it's really tough It's
really T and then elazer at one point
invented AI not kill everyone ISM right
where it's like we're really clear all
we want is for AI to not kill everybody
we don't care if it says naughty words
we don't care if it's not politically
correct we just don't want it to kill
everybody so we're not kill everyone ISS
but that didn't really get traction
because it's such a big mouthful right
so here I am back at Doomer back at Doom
debates and by the way my decision to
name Doom debates Doom debates despite
being a little ridiculous and not
respectable is this if every week we're
having somebody super prominent on Doom
debates and they're all cringing at the
fact that it's called Doom debates but
they realize it's become such a big
podcast such a serious Forum at that
point I will absolutely p the title
right because I want to optimize the
title for the role that it's
accomplishing but for now I mean I have
Doom debates.com I have Doom debates on
Twitter and YouTube It's like a solid
brand right it's recognizable it's
catchy it's fun it inspires passion in
me I don't know about you please let me
know in the comments how much does a
name make you like the show and do you
have alternate names and I'll keep them
in mind but yeah I mean for now I'm
going to go ahead and say Doomer is my
best idea as to what my what to call
myself and what to call my position but
it's an ongoing conversation I
absolutely might change my mind at some
point I might just hear a new term and
be like aha thanks for the question last
question from Alfie PT what are some of
your favorite books both fiction and
non-fiction okay fiction besides project
ha Mary by Andy Weir which is obviously
awesome I haven't read fiction in many
years but I do enjoy it when I read it
it's just I'm kind of busy consuming so
much non-fiction that I'm just like H I
don't know there's no good reason really
I just feel overloaded with all the
non-fiction stuff that I like to listen
to so I don't know I'm probably being
suboptimal anyway let me talk about
non-fiction so Steven Pinker his early
books in particular like how the mind
works and the language Instinct are just
ridiculously good you got to check out
those
books nuclear war a scenario by Annie
Jacobson it's actually a very recent
book and a related book called the
Doomsday Machine by Daniel ellberg which
I think is a few decades old but I read
it recently and it's amazing like these
two books are such critical perspective
about how doomed we are from nukes I
mean nuclear Doom is kind of the junior
warning sign to AI Doom the fact that we
could be this close to being doomed by
nuclear and have the world be mostly so
passive you know the Russia Ukraine war
with the us talking such a big game
about escalating it look I know war is
complicated and there's Game Theory but
it's like getting nuked is a really big
deal okay like I'm sorry it's okay to
make more sacrifices and even yes a
little bit of appeasement if it's going
to avoid nuclear war I know the the a
word the fact of the world can come so
close so many times to nuclear doom and
then have everybody shrug it off just
because it didn't go all the way yet and
be like H it's fine it's a solve problem
when clearly there's a 1% a year chance
that literally hundreds of millions of
people are going to die and the rest of
the world will become set back many
decades and we're just like H we can put
off peace with Russia for a couple more
years to me it's just crazy and actually
a couple a16z Partners like Ben Horowitz
and Martine cassado have come right out
and said that the proliferation of nukes
is actually what makes us safe like the
opposite of common sense like oh yeah
the fact that a lot of different
countries have nukes that's like a great
equilibrium that helps us like um so you
want to go hand out nukes to more
countries like what's the logic there
like we are very close to doomed and the
proliferation is actually not helping
but the fact that the world is so
clueless and we barely have enough
adults in the room to get us out this
long where we can survive most years
right we have like a 99% chance a year
of not nuking ourselves that is like our
crowning achievement and we're really
not ready to go into the AI challenge
with that level of social competence
that barely made us through this long on
nukes so that's why I thought it was
super eye openening to read nuclear war
by Annie Jacobson and the Doomsday
Machine by Daniel Ellsberg it's just
shocking stuff and also the movie Doctor
Strange Love amazing movie one of my
favorite
movies okay you got to read the elephant
in the brain by Robin Hansen and Kevin
simler just allaround great book unpacks
a lot of mysteries of human behavior you
know the hypocrisy of what we really are
trying to do when we do stuff great book
surely you're joking Mr Fineman shout
out to my boy uh just amazing book I
first read it in high school I've read
it multiple times since it's a classic
just like the guy's character is great
some lessons about your attitude when
you're doing science it's just a classic
go to lerach by Doug hoffstatter
obligatory book um pretty influential I
read it in high school it references a
lot of interesting Concepts in computer
science so that was pretty cool the one
thing that I didn't grasp reading that
book was the connection between the
halting problem and goodles Theorem and
the idea that you can actually just
easily prove goodles theorem as a
consequence of the halting problem being
impossible I didn't realize that I had
to go read Scott eron to realize that
connection and then once I did I'm like
oh wow so gole kind of did it the hard
way at least the way it is in go to
lerach well anyway it's a good book okay
this other book was pretty influential
it's called blitzed drugs in the Third
Reich by Norman oler I read that a
couple years ago and it's basically
talking about how like Hitler was
constantly on drugs and it influenced
everything he did in the war I'm not
sure how true it is but it's just like a
ridiculously compelling narrative I hope
it's true so I didn't waste my time
reading fiction right I I think there's
some evidence that it's true but it's
just fascinating to review and I guess
maybe before you read that book you
should should just read the rise and
fall of the Third Reich by William shy I
actually read that like a year before so
I I kind of was briefed on basically
like how did World War II go down and
then once you read it that way you go
back and read how Hitler's on drugs the
whole time and you're like wow
crazy as if World War II isn't crazy
enough really crazy storyworthy by
Matthew dicks super influential just
like oh so that's how stories work like
this guy sure knows how to tell a story
like it's crazy very moving stuff and he
gives you advice to like write down
stuff that happens in your life so you
can tell stories about it I did it for
like a couple days and then I gave up
but it's pretty awesome like it's good
to get exposure to that kind of thing do
I use any of his storytelling techniques
on my podcast no because I guess I never
really tell stories here I just like
make points so it's kind of different
but fascinating stuff the almanac of
nval ravikant it's just super classic
it's kind of a quick read but it's just
like a lot of great points to still I
don't agree with nval and everything
especially not Ai and I guess not crypto
but the points in alac of Nal raan are
mostly just like solid wisdom that
people should know waking up by Sam
Harris I just really liked it a lot of
food for thought I'm like man I got to
meditate never got around to meditating
after I read that book a couple years
ago but it's on my bucket list okay he
makes a good case for why it's like it's
not just like Voodoo think about it as
like doing science like taking a
telescope and pointing it at your own
brain or a microscope whatever right
you're doing cognitive astronomy you're
just seeing what's out there among your
possible subjective experiences so
pretty cool book good stories about
Sam's life I recommend it the fabric of
Reality by David Deutsch it's pretty
popular now to like David Deutsch
everybody's always telling you to read
the beginning of infinity I felt like
the fabric of reality was a little bit
more solid I mean they're both really
good but the fabric of reality is just
like making a lot of good points the
beginning of infinity is apparently
leading people astray thinking that like
AI is not truly creative and I don't
know for whatever reason it just didn't
tell me as much new stuff as fabric of
real maybe if you haven't read less
wrong then the beginning of infinity is
more mind-blowing so anyway they're both
really good but my pick is the fabric of
reality the selfish Gene by Richard
Dawkins just like absolute classic right
I'm just listing it because I'm just
like if I want my kids to grow up and
read like 10 books right these are the
kind of books that I would include in
the top 10 I'm just like hey check this
out and you know Darwin changed
everything right so understanding what's
going on inside every little Gene and
our body is like a pretty important
thing to know our mathematical Universe
by Max Tark I consider it important to
my mental framework because it's like
hey we're probably living in the
Multiverse there's probably a lot more
than one universe that seems like an
important fact to keep in mind it puts a
lot of things in perspective it means we
are doomed but some measure of our
existence in reality is somehow not
doomed probably because there's a huge
Multiverse in many ways yeah check out
that book can't hurt me by David gogin
it's just cool that this guy is such a
badass I read it and it was kind of
inspiring to like try to run faster on
the treadmill or like try to be more of
a a badass myself I think by now it's
farely worn off but it's just nice to
know the limit of how much of a badass a
person can be let's always get to
stretch like that so I recommend that
book mate by Jeffrey Miller and Tucker
Max after I had spent a good chunk of my
20s trying to get better at like dating
and social skills I read that book on
the tail end of that whole kick and I'm
like oh yeah this is nailing a lot of
principles that I wish I'd known earlier
it's one of the best resources if I just
have to hand somebody a book being like
hey don't read all this crap online just
read this book I think that book does a
pretty good job I think that's what they
set out to do and I think they mostly
succeeded I feel like there's some other
things I know like particular
communication skills and tricks that I
use that aren't comprehensively covered
in the book but I mean you the book
can't do everything and as a single
resource it's probably the single best
one I can think of so it's on my list
and finally I'm sure I'm forgetting a
couple great books but doing good better
how effective altruism Can Make a
Difference by will mccal that's right
I'm coming out of the closet as an EA
I'm an effective altruist I'm not afraid
to say it no I mean effective altruism
is great right people just love to get
on the other side I feel like effective
alris encourage this because they're so
self- skeptical they like to question
everything and so they make it so cool
to be like I'm not fully an effective
altruist I'm EA adjacent no F that just
be an effective altruist is great and
that book makes a really really good
defense of why effective altruism exists
and why it's obviously right like I
don't even think this is like a tough
point I think people tie themselves in
knots and they're like well what if you
actually forget to think about Game
Theory when you're doing effective
altruism and then you act actually do
something bad it's like yeah okay don't
do that don't make other mistakes but
doing altruism effectively is awesome
like helping the poor in a way that's
really inexpensive for you and efficient
is awesome so read this book it makes a
lot of great points and it's just like a
heartwarming read and then consider a
like EA Global or like reading their
Forum they're good people last question
Orie Nagle you might remember Orie from
the first episode of Dune debates my
good friend Orie asks any surprising
reactions from some of your episodes
well Orie this isn't a huge surprise I
guess I'd have given it a 50/50 chance a
priori but it's the best surprise which
is the rate of Engagement of all you
guys the number of people who are
already supporting the mission and
already seeing eye to eye with me about
what void Doom debates is filling and
being like hell yeah somebody's filling
that void nice it's a pretty high number
so I'm happy that it's like okay great
this seems to be a useful contribution
in the startup World they call this kind
of thing product Market fit but it's
like a really high bar so I guess I'm
not 100% sure I have it yet but I feel
like I'm getting really close to having
it because look it's only been like 3
months we launched this thing like in
July and you guys are quite engaged
already as an angel investor when I see
a startup whose initial customer base is
acting as excited as you guys are about
doing debates I feel like that's a
really good sign that the startup is
going to hit a nice growth trajectory
which is why I do feel optimistic about
myself like I feel like 100k subscribers
is kind of inevitable and it's just a
question of will it take one year two
years will the world end before we do it
like that's the only question it's a
uniquely awesome relationship with the
audience where you guys are being
entertained and informed but you're also
giving advice and suggestions and you're
helping achieve the mission like we're
all doing this together I'm just also
rallying everybody and debating the
other side and calling out people who
are being dicks like everybody's
contributing in their own way also some
of you guys are pledging as premium
members which is awesome too so that's
been the most surprising thing to me
Orie especially when you look at what I
was saying before which is on Twitter
this isn't blowing up so it's
interesting because if YouTube didn't
exist I feel like I would get
discouraged like I wouldn't be
interacting with you guys
this little Community that's mostly
engaging on YouTube wouldn't have come
together and then I'd be like huh this
is kind of a long slog like I'm never
going to get a th subscribers so thank
you YouTube thank you algorithm right
for putting these first people together
hopefully you guys aren't the only
thousand people like no offense right
but hopefully this is actually a
stepping stone to reaching the
mainstream because if it's just me and a
thousand buddies then after a couple
years I'd probably pet her out because
I'd probably be like look this is just
not a super high return on investment
right we're not actually reaching them
the mainstream so that gets me to my ask
right I always make this ask at the end
of every episode which is if you haven't
subscribed yet or like if you know a
friend who hasn't subscribed you have
the power to get me
0.1% closer to my goal of 100,000
subscribers if you would just smack that
subscribe button you could have that
impact anyway that is enough Naval
gazing for now thanks for indulging me
with the barrage of questions thanks
again for being one of the first 1K I
really appreciate you guys now we're
going to go back to our regularly
scheduled programming there's another
episode dropping later this week so
please keep watching and being part of
the journey that is Doom debates