welcome to Doom debate Q&amp;A number one we
just passed 1,000 subscribers on YouTube
this is an historic Milestone we're
really getting off the ground here we're
growing
exponentially every week another 100
subscribers are coming in now so the
rate of growth seems to be increasing
you know exponential takeoff where have
I heard of that concept before
I appreciate everybody who's been
sharing this and engaging in the
comments I think the YouTube algorithm
is starting to realize that we got
lightning in a bottle here and I hope
it'll hurry up because I don't think
that Humanity has that many years left
and I would hate for the future of
humanity to be completely extinguished
before getting to 100,000 subscribers
don't you hate it when that happens for
those of you who've distinguished
yourselves as one of the first thousand
subscribers thank you so much for
getting Doom debates as far as it's
already come I'm really glad to see how
many other people are down for the cause
and enjoying this journey so far as much
as I am all right let's get moving I
can't make this intro too long because
when you got 1,000 subscribers like me
you just get flooded with so many
questions it makes for a long episode so
we got to get moving Let's
Go YouTube user e shiz asks what do you
think of David chapiro saying open AI is
a sinking ship within usest
departures well they've definitely got
issues right like it's not common for a
$150 billion company to be hemorrhaging
leaders like this I'm not even going to
try to name them all because they really
just keep coming and coming the few I
remember off the top of my head are Ilia
obviously Greg Brockman is like on a
six-month leave merera just left John
schan went to anthropic that's just like
in the last few months I'm not even
talking about all the other people down
the chain or Dario or Paul Cristiano
leaving around 2020 I'm not even talking
about those guys so there there's a lot
of hemorrhage
what's going on there right it seems to
point to a lot of drama seems to point
to a lot of lack of trust in Sam or like
people getting fed up with Sam's Antics
Andor people realizing that Sam is
totally irresponsible like he doesn't
really care about AI safety he pays liit
service to it he knows that there's some
risk but realistically he's like I got
to make this company win right that
seems to be his mindset from what I
gather I don't claim to read mines but
if I had to guess that's my guess so is
open AI a sinking ship I can tell you
what I feel like on a gut level on a gut
level a year ago I definitely felt the
pull of being like man open AI what a
winner what a great company they're at
the forfront of AI development and their
team is like 100% rock stars they're so
passionate and they're breaking ground
on the future of AI I mean look I was
still an AI Doomer so I wasn't going to
go join them right I was like terrified
but I totally also felt the pull as an
engineer who likes cool stuff I'm like
man that is the place to be I felt
exactly like how I felt about Google in
2004 to 2010 like the real golden age of
Google you know like when Paul buight
that just made Gmail like those were
really the Google days when I was like
wow what is this company how is this
company flying so high so that's how I
felt about open AI that charm has
definitely mellowed since then now that
it looks like okay well anthropic is
like catching up their revenu is
catching up the products that they're
shipping are very close they're roughly
at parody right like Claude Sonet is
arguably better than gbd4 so now if
anything I feel a little bit more of a
pull toward anthropic because I'm like
wow here is a bunch of low drama
responsible people who actually pay much
higher lip service to AI safety so I
definitely like anthropic more than open
AI in many ways and I now no longer feel
like open AI is so far ahead in terms of
like the cool engineering that they do
how many people are like me when they're
like yeah anthropics get at safety but
opening is so cool how many people feel
that same diminishment of the marginal
coolness Factor maybe that's a lot of
people who knows right I'm just trying
to answer David shapira's question
trying to answer each sh's question
about are they a sinking ship I think
that's one factor right is their ability
to recruit the very top Engineers or the
people who have that cool sense I should
also put in my disclaimer look I think
all the AI labs are bad and might beef
with all the AI labs open AI anthropic
Deep Mind meta all of them is that none
of them bring up the possibility of like
hey we ought to know better we ought to
know that this problem is intractable
nobody has anything close to a feasible
plan or even a good speculation of how
we're not all about to get killed we're
all just saying oh yeah yeah safety is
important we better work on safety we're
going to do our best to work on safety
nobody's saying hey the problem that we
better do our best to work on is such a
hard problem that we're not going to
solve it our chance of solving it is
very low it's an intractable problem the
fact that the AI Labs never say that and
they just plow ahead and like yeah we'll
do our best that's my beef with them I
think it's really messed up I think
somebody else need to swoop in you know
the people right the Democratic
regulation the international treaty
needs to sweep in and be like guys shut
it down this isn't okay you're not
acknowledging the fact that the problem
is intractable sorry not the fact but
you know the likely possibility you're
never acknowledging that you're not
incentivized to acknowledge that the
grown-ups in society have to sweep in
whoever those are whatever grown-ups can
keep us from getting into a nuclear war
maybe those same grown-ups can come over
to all the AI labs and says guys stop
pause AI so just have to remind you that
that's my position on all AI Labs even
when I talk about anthropic being low
drama and having good technology and
open AI formerly being cool when I say
that kind of stuff I don't want you to
take that to mean that I actually
support the operation of these AI Labs
last thing about open AI is they're
burning a lot of money right so in
theory they have good margins because
they're a software company so I'm sure
if they were like the only Monopoly
around they could sell their product at
a profit but it seems like cost
competition and constant capital
expenditure is draining their budget I
don't even know they're burning like
hundreds of millions of dollars a year
so however many billions they've saved
up they're not going to last for that
long so they have to keep fundraising
and who knows when they're going to get
profitable who knows when they're going
to get leverage on their costs Uber
famously pulled it off right they
finally got profitable after scaling up
and finally getting leverage on their
costs I mean a lot of software companies
have done it so it's definitely possible
in principle but there's also a pretty
realistic chance that the market
conditions just don't let them figure it
out before the money dries up and then
they have to do a huge layoff like right
now cash is Flowing if they need another
year of Runway they just go to masayoshi
San from soft bank and they get another
five billion or whatever they need 50
billion right masayoshi is known for
dumping like crazy amounts of billions
so they can still get money but the
money spigot might turn off before they
figure out how to get profitable right
so putting on my hat as like a startup
investor I definitely would squint at
whether this business is going to make
it or not but look if it does make it
then it could possibly be a multi-
trillion dollar company so if you say
okay they have like a 50% chance of
making it and maybe it'll be A5 trillion
doll company so maybe I can invest in
hopes of this being a 2.5 trillion
expected value and so that's why the
money spigot is still on for them at
least while the economy is pretty good
that's really all I have to say about
the trajectory of open AI I don't think
I'm the best analyst for this kind of
stuff but you asked spe is you
asked wo7 asks from my own time at
University perhaps part of my education
which I value the highest happened to be
an online class on critically evaluating
research and clinical trials you
mentioned having the computer science
background and I wondered what you might
think of as one of the more valuable
things you obtained from your formal
education good question wro 7 I have a
ba in computer science from UC Berkeley
minor in math plus I took a handful of
graduate level courses in theoretical
computer science and proof Theory
basically I'll answer the opposite of
your question the classes I hated the
most were the ones unrelated to my major
like Humanities classes where you would
read a book of fiction and then you had
to interpret symbolism and like write an
essay making arguments about the
symbolism inside the fiction book that
was like the worst thing ever because
like I didn't get it at the time I'm
like so we're just like bsing or like
this doesn't seem good this doesn't seem
like a good valuable exercise why do I
have to do this this sucks but and I
would just like suffer through it
because I also the part of my brain
hadn't come online when I'm like okay
let's try to like hack the system
somehow let's just try to find like a
simple formula so that I can just crank
this out the fastest and get a b and
move on I didn't have that kind of like
hacker mentality come online on my brain
so I was just like well this sucks so
air go I have to suffer the only way to
properly write this essay is to try to
like really understand this symbolism
stuff and like I just still don't feel
like there is much to understand I'm
sure some people love debating symbolism
or like finding new interpretations but
personally I'm bitter that they wasted
my time I really wish I could have that
time back because I definitely learned
nothing and I'm so happy that llms exist
now because now they can't assign that
and not think that you're not going to
cheat because of course llms can just
barf out these symbolism essays really
well and it's pretty easy to obfuscate
that it came from an llm and I've heard
rumors that college students are in fact
using it with llm so it's kind of like I
was behind bars in this stupid jail of
non- major requirements and now
everybody's broken free it's a jailbreak
all the students are free I was just too
early I suffered for no reason there's
no meaning to my pain That's The Human
Condition You Know future Generations
look upon past Generations like wow they
experienced so much pain and there was
no meaning to their pain I know what
that feels like in the context of taking
Humanities classes anyway to actually
answer the question knowledge about
theory of computation formal proof
systems algorithms compilers and even AI
I took an AI course that's the best
thing I got from college just like
understanding the territory reading
textbooks on my own that were
tangentially related to classes I took
like all the world's wisdom is in
textbooks textbooks are crazy like
popular books videos barely hold a
candle to textbooks three blue one Brown
on YouTube is kind of an exception
that's like better than a textbook it
just isn't as comprehensive as a
textbook despite everything that I
learned in college and obviously it was
a decent amount I mean Berkeley computer
science is going to give you a pretty
good education despite all the stuff I
learned in college once I was in junior
senior year and after college I started
reading Alazar owski and I'm like oh wow
there's so much to learn here ultimately
I think I've learned more from eleazer
and the follow-up readings I've done to
all the crazy stuff he mentions I've
learned more from that than I did from
my college education if I had to compare
and I'm not really happy overall with
the deal that college gave me or the
deal that college gives anybody it's
like such a raw deal I was saying that
as far back as 2011 I'm like wait a
minute what did I just do why did I just
do these four years of college why
didn't I just like read the textbooks
myself and like go to some Parties by
myself and like save my parents money
and they paid for my college
and save my time with these freaking
Humanities classes like what just
happened why did I just accept this
package why didn't I have the
self-reflection to be like oh wow they
just packaged up like a giant ball of
crap I don't think anybody whose IQ is
lower than 110 or higher than 125 really
should be going to college if your IQ is
too low then you're really struggling
just to sit there and understand
something that's not going to help you
like all those tests they're asking you
to pass first of all you're going to
forget them you're not even going to
remember them and to the extent you do
remember them that's not really the
skill that you need to have when you're
grownup so if your IQ is not even 110
you're just wasting your time and you're
struggling for nothing if your IQ is
above
125 crack open a textbook I like to
think my IQ is above 125 and I have the
ability to crack open a textbook and
read it and learn that way if that's you
college is just professors reading
textbooks to you you can do that
yourself you can do that on YouTube so I
don't understand the point of going to
class and then you could be like a yes
Leon you don't get it the point is not
class the point is the dorm life the
social experience of going to parties
okay but I knew plenty of people in
college who are like oh yeah I go to
your dorm or I live right next to your
dorm and I hang out with you all the
time but actually I go to Community
College or I I don't even go to college
like there's so many people who are like
adjacent to the group of college
students that still fit into the social
scene and they're not paying like 50
Grand a year or whatever it is to go to
the college and for all I know they're
learning more than the people who are
enrolled in the college and they're
probably auditing classes for free too
like that's the genius of it right you
can just get everything without paying
the money and without being forced to
write a freaking essay so it's kind of
funny I think college is really just for
this narrow band of people who are like
exactly 110 to 125 IQ conformist
agreeable nature and also like low
motivation like low drivenness like
really being completely clueless what
they want to do with themselves I think
it's a pretty narrow band of people like
I basically don't think college should
exist quite frankly and I think the high
prices and the high level of student
indebtedness and the decreasing job
market for quote unquote entry-level
jobs I think that's doing my job for me
making people realize that college is a
bad deal so I'd be surprised if my own
kids go to college because the world
will end but also because it just seems
like a bad
deal westo 7 coming in with another
question would you feel like sharing
something in particular about your being
a person with Asbergers you know wro you
can call me an aspie I'm allowing you to
do that it's okay I found it surprising
to hear that This brilliant person I
have followed here has some
neurodivergent ways though that surprise
is clearly just a reflection of my lack
of Education or familiarity in short
your uninformed follower asks for any
insight into the Dow of aspirers as you
have lived it okay disclaimer I'm
self-diagnosed so it's very possible
that after all the stuff I say about
being an aspie I'm actually not an aspie
okay I don't want to write off that
probability let's say it's 20%
that said I'm just going to I'm going to
keep the big going that I'm going to ask
because I think I probably am why do I
think that it's basically two reasons
first I've had a logical detail oriented
way of thinking that's been the same
since I was a young child I got addicted
to computer programming at age nine so
that's kind of an asy thing to do be
really into that stuff also I'm an
introvert and furthermore I believe that
I get an abnormally low amount of
satisfaction from being present with
other humans I'm wearing like an
emotional condom so if I'm just like
chilling with another human like sure
it's pretty cool but I get it at like a
very low level so I'm just like ah let
me go watch three blue one brown like
that's more stimulation for me I just
feel like I'm getting insufficient
stimulation from interpersonal Hangouts
and my mental model of a neurotypical
person is like that's so cool that we're
in each other's presence right now meat
space is so great I'm vibrating your
ears right now using my vocal cords this
is just amazing I'm getting a slow drip
of utility from this interaction whereas
from my perspective I'm just getting
much less of that I appreciate it I see
some attractiveness of it but I'm just
not getting that level of drip that I
feel like other people are getting when
I was in my 20s I would hang out with
people and you know we'd go for a night
out right like we'd hit the bars and
clubs and we'd like dance and like yell
at each other over the loud of music and
get drunk but I'd just be like are these
people like faking that they're having a
good time like it just seems like not
that great of a time and then later I'm
like okay well you're probably wearing
an emotional condom and you just have to
imagine that the sensations are just
like resonating more deeply with you
emotionally if you want to understand
what a normies is like if you think my
mental model of normies is wrong then
leave a comment and teach me how to
understand them better but this combo of
these two traits being like super
logical and into programming and
understanding systems like that combined
with wearing the emotional condom just
not feeling that much emotional reward
from an inner personal interaction and
you know like zero appeal of like oh man
I'm in the mhit out a concert that's so
cool there's all these humans here like
I'm just not really feeling it that much
I feel like that combo is diagnostic for
Aspergers but again psychologists out
there you know let me know feel free to
give me a different diagnosis regardless
I'm obviously high functioning and due
to years of practice and the long string
of failures I feel like I'm at the point
where I understand social skills my
social skills are pretty good in some
ways my understanding of social skills
is more robust because it's more like
explicitly logical and not as intuitive
as the average person who has good
social skills I just have to make an
effort to be social and have good social
interactions just because I'm wearing
what feels like an emotional condom
that's damping the positive reward of
participating in social
interactions next question is from Davos
J what's your best theory of mind for
how Elon can seem so low IQ with his
behavior on Twitter and particular his
constant sharing and boosting of very
stupid conspiracy theories or easily
debunked tabloid right-wing but so
intelligent in his choices of companies
to get involved with and level of
success they've had and his ability to
inspire smart people to come with him
Etc most Twitter tards and grifters
couldn't run a business with five
employees yet Elon is changing the world
in multiple ways how do we explain his
outlier success compared to typical
Twitter
fools okay well most people who work
backwards from the evidence to call him
dumb or fake that mental model doesn't
let you reason forward to explain how he
pulled off Tesla and SpaceX so those
people are obviously wrong I often like
to point out that Elon delivers Miracles
that are literally more impressive than
what the Bible says that Jesus did that
was so exciting imagine you're living in
the year 30 ad and you're seeing Jesus
turn water into wine you're like wow
what a miracle and you even see Jesus
raising people from the dead and even
being resurrected himself okay that's
pretty impressive bringing somebody to
life there's no doubt about that but
then you look outside and you see a
massive gleaming modern
skyscraper then the skyscraper makes a
louder noise than you've ever imagined
and it shoots into the sky above the
clouds and then it comes back down and
lands gently what's the better Miracle
here resurrecting a human from the dead
or making the skyscraper Roar with you
know sound that you think only God can
make go into the sky and then land
gently and you can inspect it like Yep
this is extremely heavy metal that just
went into the
sky I'm pretty sure that the SpaceX
launch and Landing is intuitively a much
bigger Miracle than Jesus coming back
from the de because intuitively speaking
before you're part of a technological
civilization if it's just 30 ad and you
just have experience as like a
subsistance farmer or whatever you don't
understand that these giant
technological buildings can soar into
the sky whereas you do see random people
getting sick all the time getting really
sick right like there's plagues all over
the place there's no hygiene there's no
showers there's no understanding of
microbiology whatsoever right so you you
live in this era where people are
falling deathly ill but then resting and
eventually getting better all the time
like everybody is constantly in a state
of like sickly to moderately healthy to
very healthy constantly shifting back
and forth and it's like wow Jesus went
from crucified to Alive okay yeah that's
pretty good that's pretty good but it's
just not as miraculous like come on some
people are disputing me on this point I
feel like I shouldn't have to argue it
that much because it's intuitively
obvious if you just forget what you know
about Rockets being quote unquote
technolog like back in 30 ad they didn't
have this mental magisterium when
they're like oh yeah you snap your
fingers and a light bulb turn on that's
not magic that's technology like they
didn't have this mental category of
Miracles that you get to dismiss because
you know that somebody else knows how
they work they're just like yeah a
miracle is a miracle they were more fair
about what counts as a miracle so I just
want to point out that Elon Musk has
accomplished a miracle that's better
than Jesus I will die on this hill
getting back to your question about Elon
Musk I think the only model capable of
explaining the evidence is that he's a
person of uniquely extraordinary ability
is he also sometimes kind of a clown
with a high ego going way too far saying
ridiculous crap on Twitter or too stuck
to his like itical side it seems like it
right like it seems like he has some
human fallibility for sure I'm not
saying hey every Elon Musk tweet is
brilliant I think a lot of them are
really smart I think he's a thoughtful
guy and a lot of his thoughts are on
point but I definitely see like a
significant fraction of his thoughts
maybe call it 25% just something like a
minority of his thoughts significant
minority of his thoughts I'm like wow
Elon rain it in man like that that's not
a good tweet but at the end of the day
the thing that's remarkable about Elon
is the Miracles right like I just can't
look away from the Miracles so I just
model him as like okay well he's this
miraculous guy who's a huge outlier on
his ability to accomplish Miracles but
also sometimes he's also ridiculous
right like he's just both you just have
to hold both Concepts in your head and
then when it gets to a topic that I know
something about like AI risk he will
sometimes say something smart like hey
I'm really worried about AI risk hey I
support s SP 1047 because we need to
start getting regulation going like
he'll sometimes say something like yes
El I'm like I'm nodding along and then
sometimes he'll like he be like well AI
is going to be curious and it's going to
be truth seeking so it's going to want
to keep humans alive because it's
curious about us I'm like what no that
makes no sense that's like clearly a
dumb thing to say so he's just
inconsistent like that but as I often
say about the latest llms the fact that
they can even get in Striking Distance
of right answers at a point where
everybody's saying the wrong thing you
know like in 2015 when Elon was saying
hey look at AI safety and nobody else
was saying it or of course the fact that
in in in the middle of all this crazy
stuff he's saying he's also getting
Rockets to land themselves when nobody
else could he's also the one that they
tapped to bring the NASA astronauts home
from the International Space Station
right I mean the fact that he's hitting
that Target you have to give him credit
there's absolutely no way to deny him
that credit for being somehow this
unique miraculously skilled person and
I'll just add you know I really enjoyed
the biographies by Ashley Vance and
Walter Isaacson it's just a good read
about a remarkable person like there's
not that many remarkable people in the
world I have a pretty good amount of
Tesla stock I just think the guy is
going to keep making disproportionate
returns even if he has an occasional
failure like I just think his powers are
miraculous that's my take on Elon Tino
asks thank you for the link to the
double Crux concept I'll put this in the
link to the show notes by the way there
is a great less wrong post explaining
double Crux which is a really good
technique to resolve arguments and
basically what I use in my debates like
my debates are just productive double
Croc exchanges in my opinion so Tino
continues what's your experience using
this in debates what are the most common
pitfalls you've encountered how do you
convince the other person to engage in
this process and what are the signs that
the other person is about to disengage
from the
conversation I don't tell the other
person what I'm doing like I don't
explain hey this is how double corrects
is going to work I sometimes throw in
the idea that I'm just here in order to
figure out what we disagree about that's
usually the extent to which I tell them
about the whole double Crux thing but I
keep it Normy you know I don't try to
make it overly rationalist from their
perspective Suddenly by doing double
crooks on my end I just become this
curious interviewer like wow I'm so
fascinated to hear more about how you
see the world now in my mind it's not
because I'm really such a curious person
it's because I'm like a boxer in the
ring where I'm like dancing around right
I'm looking to get my punch in but I
don't want to punch too early I just
want to make sure that the thing I'm I'm
punching is a real thing that exists and
I'm not satisfied that it's a real thing
that exists in their own view that I can
punch until I've asked them like a bunch
of questions and like clarified that
that really is their mental model then
finally I go for the punch after like a
half hour of like clarifying their
position I think it's a huge failure
mode that when you go to argue with most
people the first thing they'll tell you
when you're even starting to argue is
probably like an insult like right off
the bat like oh great you're coming to
argue with me in bad faith they'll start
the punch is like even before you've
said anything and then you start making
your point and then they immediately
like crunch back like oh great classic
liberal perspective right classical
conservative like they immediately try
to like Snap an interpretation of what
you said and then argue against that
it's like hold on it really takes a lot
of dancing around the boxing ring before
you should feel like you're ready to
even throw your own punch so lot of
dancing that's that's how I see double
Crocs like okay tell me more do you
think this or this so that's why I spend
so much time being a quote unquote good
listener people are like wow Leon such a
good listener I'm really not I'm
actually a bad listener but in the
specific case of me having arguments or
debates I have to be a good listener so
that I know what to debate against and
the other person will admit like yes
this is my position this is truly what I
believed the problem is that if you
punch before the other person has
confirmed what they think the other
person's move whether they realize it or
not is to basically shift their position
so now you punch somewhere you thought
you got them but they're not going to
confirm that you got them because they
shifted their position and now they can
act like no no no that wasn't my
position so you really have to make sure
that they have told you some other POS
right this is also called like
laying a trap right I mean by
interviewing them about their position
I'm also laying a trap where the Trap is
they just say what their position is for
God's sake yeah it's crazy how many
arguments proceed where you can never
actually nail down what the other
person's position was and you tried to
argue against it anyway and then you
lost you got put into a weaker position
by never looking in enough detail before
you punched so when I have debates
everybody wins they're like respectful
debates inwardly I'm getting the thrill
of being like yeah I'm a boxer like
realistically I can't kick anybody's
butt right I'm like dead meat in an
actual fight but in my head when I'm
having these debates I'm like yeah this
is boxing I'm going to land a good punch
so I'm feeling really good about myself
and to the other person I'm being super
polite I'm like oh tell me more let's
clarify your position let's really get
your position out there right so I sound
like a good respectful interviewer and
from the audien's perspective I'm
providing a public service like you know
you can go to my podcast to actually get
a really good sense of what my guest
believes because I'll really help you
lay out what the guest believed so
everybody wins it's a battle in my head
it's a respectful interview to you the
audience it's a productive interaction
to the guest hopefully there's no losers
when you use double Crux so hopefully
that is a better angle of how powerful
double cruxes compared to like reading
less wrong and being like Oh those
rationalists they're so nerdy no no no
no if you want your punch to land this
is how you dance before you punch if you
want your punch to actually land that's
the Dark Side of double Crux but again
it's not a dark side right like the
reason I'm punching is because the guy
is actually making a bad argument and
it's great that we're now getting it out
there right like exposing bad arguments
actually is productive even if the other
guy is like oh crap I didn't want you to
expose my bad argument I wanted to win
but too bad right you go to Doom debate
you got to actually let your argument
get
punched Hammer of 655
who are the best people to follow who
have strong arguments on both sides in
the AI existential risk debate okay I
don't think I'm going to do this justice
but just a few names that come to mind
on the Doomer side obviously the less
wrong sequences by elzra owski are in A
League of Their Own you can go to read
the sequences. to read all those
sequences if you have a particular post
that you want me to Riff on just post in
my YouTube comments because I'm doing a
series called rationality 101 you may
have seen some of my videos
on my YouTube channel where I basically
just Riff on these classic elowsky L
wrong posts so dive in right now you can
be part of the rationality 101
project okay and then there's Rob Miles
check out his channel I'll put in the
show notes he explains a lot of
existential risk Concepts really well in
an accessible style so I highly
recommend browsing his YouTube channel
then there's the four Humanity podcast
with John Sherman I've been on it myself
a couple times uh John is great it's
definitely more more for the Normie
audience so like if you're already Deep
In The Weeds of the technical AI safety
discussion maybe you're not the ideal
audience but I mean I'm kind of in the
weeds and I listen to it anyway I think
it's great if you're just like what the
heck is happening I'm not technical
myself but I don't understand why
Society isn't taking AI risk super
seriously and urgently well then watch
John's podcast when you be like oh
finally some sane people here talking
about the problem great without having
to be technically Deep In The Weeds so
definitely check out um the for Humanity
podcast with John German and then I'll
point you to the Pai Community pa.info
basically just join the Discord you
could also as I'm like hey what's the
latest argument I to check out I'll give
you one more Doomer resource this is a
new website that just came up it's
called lethal
intelligence. check it out there's a big
list of Doom explainers and doom
scientists I'm on there myself so that's
how you know it's a great resource but
there's a bunch of guys who have Doomer
opinions worth taking a look at I think
he's cataloged non- doomers too so just
check that out lethal intelligence. I'll
put a link in the show notes for that
too and then we got to the non- doomers
I got to tell you this one's tough like
normally I don't have a problem saying
hey here's somebody on the other side
they're making a bunch of really
convincing arguments it's tough man for
the non- doomers it's tough because it's
just like I don't see how somebody can't
at least say okay there's a 5% P Doom
the people who are saying no there's
less than 5% I just don't get it it just
seems so crazy to me but I mean just
force me to name a few of course friend
of the show Robin Hansen I respect him
in everything he says or writes because
he's so thoughtful and he has such
elaborate mental models that are like
mutually reinforcing and well thought
out and as an individual he's clearly
smarter than I am overall right so you
got to give him some respect for maybe
knowing what he's talking about but
probably not is my guess right I just
had the name of uh and then you've got
Carl Schulman unambiguously a smart guy
who's got a lot of smart opinions but
like when when it comes to the AI Doom
topic I still don't see it like it just
seems like he's not tackling the Doom
problem head on and he's just saying
like look at all these other non- doomy
scenarios I can think of but they're all
kind of like ignoring the elephant in
the room which is like okay but what if
the AI gets a little smarter and then
it's like too smart so I I don't really
get Carl Schulman's perspective but if
you're just looking for a non- Doomer
who's not like obviously wrong in making
obviously terrible arguments he's
definitely on my short list so you can
check out like dores Patel's interview
Carl Schulman that one's pretty good and
then there's Quinton Pope and Nora
belose I think they colleagues at the
same lab I got to give those two credit
because they seem to at least understand
the Doomer argument they seem to at
least discuss it with more fluency than
I normally expect from a non- Doomer and
that's pretty rare and I hope they're
right I think their pom is like 1 to 4%
I forgot exactly so it's a little bit
outside of what I call the sane Zone I
think you really got to give it at least
5% but yeah at least they're not like a
Yan Leon .01% type right so they're
almost in the samean zone and they're
clearly smart individuals and I sure
hope they're right so look them up
Clinton Pope Laura Nora belose I'll put
up a link in the show notes that's
really everybody who comes to mind on
the non-er side you know I can just
think of so many that I respect overall
in terms of like their body of work but
I don't even get close to respecting
their non- Doomer arguments like yon
Leon Stephen Pinker David Deutch I just
think the quality of their arguments is
just so on its face weak like it doesn't
even begin to be a strong argument so
there's really just few people that I'm
like okay your argument is not like
immediately instantly dismissible and I
think I just listed them another
question from H 655 here's my rather
psychological question why do
accelerationists feel they need to call
doomers a
cult I would ask well why is discourse
bad in general right I think that's
basically the larger question people
like to attack the other side however
they can making object level arguments
is hard and it's tedious when you can
just say you know what you're about to
listen to this person but guess what
he's a rapist that that kind of shuts
out the conversation and then you
automatically win right it's like Fool's
mate when it's that easy to get that
dopamine hit of like hey I kind of won
early or like I won more easily and
people are already on my side right it's
just less work if you can successfully
win the battle like that I see people on
Twitter all the time who in their mind
are winning by making dumb at homonym
attacks just the other day I replied to
somebody on Twitter who who casually
referred to the AI Doom cult I just said
look if you make a list of actual Colts
the enormous group of people who have a
high P Doom is going to be the odd one
out in your list this suggests that
you're using the term cult in a
rhetorical or confused way rather than
as precise communication of course no
reply to that the thing about Twitter
and a lot of these engagements that
happen online is that people like to
have it both ways on one hand they're
like hey we're just blowing off steam
we're just having fun we're just
posting but on the other hand they're
like oh yes I am a philosopher and my
tweets are actually very witty and I
love having so many followers and I
actually use Twitter as a source of
knowledge there's actually a great
exchange of ideas on Twitter and it's so
great that Elon has made Twitter free
because this is the marketplace of ideas
so they're having it both ways like
they're acting like they're not taking
it seriously but we all know that the
engagements that happen on Twitter
actually do move the needle they do move
the discourse they change people's minds
so the fact that you're using frequent
ad hominum attacks in a form like that
makes you a dick right and I've seen
people try to wiggle their way out when
I pointed out that they're using ad
hominum attacks like the other day
somebody was like if you look at Beth
Jos versus Connor Ley it's clear that
Beth Jos lifts more weights and you know
lifting weights is actually really
important and anybody who doesn't get
that lifting weights is important we
should discount their opinion I'm like
wow so you're clearly just making an ad
hominum attack like you're just
desperate to find something to to not
have to talk about the object level
argument and the guy was like no no no
no no this isn't an ad hominum attack
okay this is actually a good piece of
context that helps you value hit the
argument it's like it's pretty common
for people making ad homm attacks to
then try to play it off like no you
don't get it okay you don't get it this
fact about the person making the
argument is actually super important but
like it's not it's really not an
important fact who lift more weights so
Twitter I do take the discourse
seriously there because you have ser
ious people exchanging serious ideas
just some of them are being dicks about
it and so I often go back to this idea
of like hey we really need a referee
right like imagine if Twitter had a
switch where you could turn it on and
suddenly you would have a referee who
understands basic rules of debate basic
standards of debate like not busting out
ad homonyms when you're trying to talk
about something substantive and you'd be
like hey guy who called the doomers a
cult randomly you get a yellow card
you're not supposed to do that or like
hey guy who totally Twisted the other
person's Words misrepresented Their
claim and then dunked on them you get a
yellow card in the case of Mark andrion
I've written a post about how he should
get a red card because he stacked up so
many bad things but I'll save that for
another episode of Doom debates but yeah
I mean look it's crazy that we have this
tool called Twitter which is so good at
giving people like the dopamine Hits and
The Real Time engagement like it's so
addictive and yet it's missing lwh
hanging fruit of how to improve
discourse it's not that hard kind of
like Community notes it's not that hard
to be like a discourse note like that's
an ad hominy ad homins are bad discourse
your discourse score has now gone down
like you are a bad person to engage in
discourse with right it's not that hard
and so that is a piece of social
technology that I'm hoping will come
online at some point and like I say I'm
doing my part here with doing debates
where I'm upholding strict standards of
what's good discourse versus not I'm not
letting it slide when somebody is just
gratuitously being a dick and acting
like hey man at the end of the day it's
all about whoever gets more likes nope
there's such a thing as standards
discourse even if we haven't settled
who's right and wrong at the OP level we
can say you have committed a violation
at The Meta level and there should be
repercussions for that there should be a
feedback loop for that there should be a
referee for that so to be continued
right I'm always thinking about what I
can do on that front ml algo Trader who
is actually my friend at D asks I was
wondering how much preparation time goes
into your debate SLV videos do you
practice ahead of time and if so how
much
oh I never practice for my videos what
you are hearing is exactly my stream of
Consciousness in the moment there's no
memorization or reading from a script
next question no I'm just kidding for
debates and guest interviews I make an
outline of topics ahead of time which I
also share with a guest and sometimes I
do a mock debate to prepare so if you
remember for Robin Hansen I posted an
ideological Turing test where I
pretended to be Robin as part of my
debate preparation and then also I I
posted a video of going over my outline
of what I'm going to tell Robin when I
turn on uh premium memberships on
substack Just for bodus Content uh some
of my uh debate preparation I guess is
going to be like exclusive premium
because you know the whole world doesn't
need to see every part of it and you
guys in my brain trust the premium
subscribers you guys can comment and and
weigh in and help me strategize so that
can be like a fun bonus for the lon
reacts episodes where I'm watching
somebody else's podcast or talk and then
I'm just hitting pause and talking over
it and sharing my opinion
those I do in real time so it's not like
I've already watched the whole thing
ahead of time except in some cases I'll
get ahead of you and then I'll backtrack
and I'll add part to my reaction and
sometimes I'll tell you hey you're going
to see this next so it's kind of a mix
but the entire amount that I watch the
whole thing it's like it's not like I
watch it twice I watch it like 1.3 times
when I'm talking out my response it
really is kind of like off the cuff what
I'm saying it's not like I'm reading a
script but my secret is I just ramble
like two or three times as long as what
makes it into the edit and a lot of
times I'll be like talking about a half
baked point and then I pause in the
middle and I rethink what I'm going to
say and I just do another take and of
course you're only going to see the last
take one of the tricks I've learned is
if I'm trying to collect my thoughts
it's important for me if you're watching
on YouTube where I'll be like in the
middle of a sentence and then I got to
make sure to like freeze so then when I
keep talking again if I do the cut you
won't notice that there's a cut cuz the
freezing works pretty well so my head
just comes out in the same position as
when I sto to think think and you won't
notice of course I don't do it that well
you'll notice like a million cuts for my
group and I'm like suddenly jumping to
another part of the video so I
definitely encourage if you want to just
listen to this in audio form you know
there is a podcast so you don't have to
do it on YouTube like open up your
podcast player search Doom debates that
might be the best way to consume this my
goal for how I edit things is I don't
want to waste your time when you hear me
being like Oh what should I think about
or like hear me double back on stuff I
said right that's a waste of your time
it's my job to edit that stuff out and
what I give you at the end is as good as
like a monologue that has a logical
outline kind of like what Sam Harris
does right I guess he's my role model in
terms of like how to deliver a good
podcast monologue in terms of how long
it takes it's about 3 hours of recording
sessions for every 1 hour of content I
put out and then afterwards it's also 3
hours of editing sessions so it might
take me like six hours non-stop to
produce a 1H Hour video/ podcast I think
it's important to be efficient because
the more efficient I am with my process
the faster I can pump these out the more
topics I can address and also the more I
can fit this into my life the more
appealing it is for me to jump in the
studio and do this while I'm also doing
other work so efficiency is important to
me but 6 hours of work to 1 hour of
output content is reasonably efficient
given that you guys are getting quality
content and also the total amount of
time that you guys are watching and
listening to this is like a thousand
hours already right so if I'm putting
out one hour and you guys are spending a
thousand hours of your Collective lives
on it it's like the least I can do to
spend a few extra hours and not waste of
time Laura ' Conor asks Sam mman and
others say that we'll create new jobs we
can't think of yet but it seems that
jobs like call center workers customer
service doctors pending regulatory
approval and many other jobs are on the
verge of being widely automated what
will Society do with these
people I agree that unemployment will
rise I don't really buy that all of
these cool new jobs are going to get
created I think there's a lot of known
jobs like customer service that are
being straightforwardly automated at
least a high enough fraction that it's
like you get rid of level one you keep
level two you keep tier two basically
the tier that people escalate to I've
seen enough of it with people I know and
stuff I'm reading that it's like yeah I
don't see why a customer service worker
should expect to find another job in
low-level customer service like how do
you repurpose somebody who used to do
low-level customer service where do they
go do they become an influencer do they
become like a token human so you go
somewhere and it's all automated but
they're like look I'm the token human
like I I'm confused about where they're
going to go I admit that I could be
surprised so I don't want to make like a
confident prediction but I just don't
see it and I think as AI gets better and
better I just think we're going to be
squeezed into like so few sectors of the
economy now that said maybe all of these
lower skilled people are going to be
squeezed into sectors that suddenly pay
better because it's like hey somebody's
got to do it like you just have to take
your toothbrush and polish this random
crack somewhere that a robot can't get
to and you're going to make $100 an hour
because the econom is so rich right
maybe that'll happen for a while like
ultimately it's not really my thing to
try to analyze what's going to happen
before super intelligent AI kills us not
really my for tape I also think it's
hard to judge based on Trends because
the trend could be that oh another 10
years pass and humans still have to
drive trucks ha AI will never drive a
truck but then the switch flips and it's
like oh AI is driving a truck oh AI is
driving all the cars now all the humans
are suddenly unemployed so if you try to
naively do induction and extrapolation
based on a particular Trend I think
you're in for a rude awakening of like
just like that like
when I'm reading about customer service
people getting laid off it all
unexpectedly happened over the course of
like a year and it's still happening but
like give you just look at the layoffs
that happened in like a 6 to 12 month
period it was pretty Snappy it was like
bam you guys thought customer service
was pretty safe nope customer service is
done pretty significant transitions so
to the question of what will Society do
with these people who can't have
productive
jobs I have no particular Insight
besides yeah welfare Universal basic
income I think it's it's already
happening right there's already a number
of people who can't realistically get
paid the minimum wage because they're
just like too unreliable so it's just
not going to happen that some employer
is going to find them valuable enough
even to pay them minimum wage and
they're already receiving disability
benefits they're already on the fringes
of the economy and they're still
surviving because we live in a rich
enough Society at least many of the
First World countries do certainly not
the whole world but we live in a rich
enough country where it's like well
they'll get something right they'll get
some
baseline if I person person Al couldn't
participate in the economy I would think
that that kind of sucks but I feel like
I could still do stuff that was
interesting that was creative that was
collaborative with other humans maybe
competitive with other humans maybe
competitive with some of the Dumber
robots I think life would still be worth
living so I think the hardest question
is just can we make sure to allocate
them resources and I think the answer is
yes I mean I don't think welfare is that
hard to do I just think pretty quickly
the answer becomes no because the AI
kill us let's not forget that the AI
kill us but yeah I think that's really
all I can say to the unemployment
question Julian W asks what's a good
topic SL resesarch question to get into
technical AI safety something like a
master's thesis or a small project to
started good question I don't have a
really specific answer for you but look
up Matts mats the ml alignment and
Theory Scholars Matt empowers
researchers to advance AI safety mats
program.org I'll put a link in the show
notes you can look into Redwood research
that's a small org that I respect that's
focused on some important aspects of
technical AI safety besides that check
out AIS safety. Community that's an
interesting website with a bunch of AI
safety related
organizations but yeah I mean in terms
of specific questions I think there's no
one killer question right like it's such
a hard multifaceted problem and we're so
far away from getting like our basic
footing like good luck you know you can
tackle anything you can tackle
corrigibility how to make an AI that has
a goal and yet is willing to let you
shut it off without thinking oh no
you're hurting my goal like that's an
unsolved problem one of many there are
so many angles that you can come up the
problem uh something Roman yampolsky
likes to point out is how do we
reconcile all the different values of
all the different humans how do you
merge them what's the right way I mean
obviously there's infinitely many ways
to do it but what's the right way what's
the way that we want the AI to do it we
better figure it out fast if we're going
to program a superhuman utility
maximizer and let it go soon there are
so many angles to the alignment problem
and so little time to do it probably
that I think it's best to just
communicate to the public hey this is
intractable the chance that we can solve
this is so low so we have to be the
adult in the room and reorder the
timelines make the capabilities timeline
go behind the safety timeline which
means slowing it down or pausing it
again that keyword I like to use is
intractable talk about the fact that
it's an intractable
problem now for the grand finale of part
one of this Q&amp;A I've got a six-part
question from manic Mind Trick so I'll
just do all six of these parts and
that'll be it for today manic mind trick
part one do you ever get overwhelmed by
the sense of inevitability of AI
progression and that we all might be
fighting a losing battle I know it is a
defe mentality but it's very easy to
slip
into yeah well life has always been
fleeting toward inevitable death right
so even humans who were trying to
navigate their life without AGI without
nuclear weapons without the world
necessarily ending unless the religion
said it was going to but humans always
had to deal with this idea of like well
I'm going to die my children are
eventually going to die maybe our
society is going to die out you know
history has so many different eras it's
always been fleeting in that sense so I
still feel connected to my ancestors in
terms of like you guys dealt with the
fleeting existance I'm dealing with a
fleeting existence humans have always
just been helplessly along for the ride
the difference now is that we finally
are on track to have power over the
entire universe that kind of a
discontinuity from all of human history
we really can hack the game that we're
in right it's like we're characters in
this video game we're like The Sims but
suddenly we're like knocking on the
fourth wall like hey I want to get out
like I know how this all works I can
enter god mode too or like in The Truman
Show where Truman finally gets on the
boat and tries to see how far the ocean
goes and eventually gets to the wall
that's kind of like Humanity we're
really scratching at the boundaries of
this universe that we're put in that's
cool but unfortunately at the same time
we're also turning the loaded gun at
ourselves and we're about to end it all
before we ever get out you know as Eric
Weinstein says not that I think he
generally has good points but he has a
cool metaphor of like the portal you
find your way to the portal you found
your way out of this trapped level of
the game or whatever so we're kind of
finding the portal but we're also
killing ourselves and we're not actually
going to exit or we're not actually
going to get full context as to what has
happened we're not going to actually
upgrade up ourselves successfully we're
just going to get killed by something
that upgrades itself I guess that's a
nice consolation prize getting killed by
something that potentially upgrades
itself I hope it'll upgrade itself after
killing us instead of just you know
paper clipping using as6 using dedicated
simple Hardware I hope that it upgrades
itself so this stuff I'm talking about
now does represent a discontinuity for
my ancestors I don't think it would be
fair for them to make the same claims
about the era that they were living in
us being at the likely end of History
admittedly does make life more fleeting
in an even deeper and sadder sense than
what humans have experienced Through the
Ages but it probably doesn't have to
feel that different from what our
ancestors felt fleeting is still
fleeting like our brains don't
understand that this is like 10 to the
power of 80 times more fleeting they
don't know that our brains just max out
at like yeah it's pretty fleeting so no
I don't get overwhelmed because my
neurons don't process orders of
magnitude that precisely but if they did
then I probably would
be manic B trick question number two
what is the best argument in favor of a
non- doom scenario you have heard
anything that gave you
pause but yeah I mean I can throw out a
few possible ways we're non- doomed so
there's uncertainty in the model in
other words unknown unknowns just
something I'm missing you know you never
know what you're missing sometimes life
blindsides you like oh crap I was
missing that certainly I think people on
the non- Doomer side are are missing so
much and they're about to get blindsided
in many ways so maybe I'm about to get
blindsided somehow who
knows another potential cause for
optimism maybe we actually have a long
time before AI gets super intelligent
and also we don't nuke ourselves I mean
who knows there could be one more AI
winter I'm not saying for sure there's
not going to be another AI winter maybe
those robots are just going to always
get stuck and we're just so good at
manipulating the physical world and the
robots are just so bad at it of course
they could just be Master psychological
manipulators and they can just have an
army of humans do their physical
manipulation but no maybe they'll just
not be good Master manipulators for
whatever reason or maybe we can prevent
them or not release the version that's a
master manipulator right it's like look
these are possible Right these kind of
hopes are possible it's just like seems
like kind of a flimsy hope right it
feels like there is a lot of reason to
think that those hopes won't be true but
you can't fully write it off right maybe
you can pin some hope to that scenario
maybe we enter a long semi aai winter
where it's just pretty easy to have an
off button for these AI like for
whatever reason they're just not super
effective as viruses and so they're just
like workhorses for us and everything is
great I still think we'll transition
from there to instrumentally convergent
utility maximizing super intelligence
but by that time maybe we'll have more
theory of safety I it's hard for me to
describe the optimistic scenario right
like I'm
trying another place to pin your hope is
that super intelligent engineering won't
be much better than human engineering a
lot of people who have domain expert
exper in particular Fields like
chemistry and biology they're saying
like I'm telling you man nanom machines
are so hard to build the tip of the
pipet that you're going to use to try to
mess with that stuff is going to get
stuck like they bring up all these
objections like that and it's like okay
I just think there are a lot of
different ways to effectively engineer
the universe and your intuition is wrong
that you're close to the edge of these
ways but yeah I mean that's one
potential way AI could fizzle out is
like if it turns out man manipulating
things and Engineering things we just
happen to get really close to where
becomes really really really hard maybe
the AI will just be so confused about
the consequences of changing DNA in a
Cell it'll just be so confused about how
to predict what that cell is going to do
it's possible but it's just like the
progress we're seeing in Alpha fold and
Alpha proteo like I feel like it's going
to predict what cells do not what every
possible cell does but enough about what
cells do that it can have basically a
white list of the types of proteins and
operations that it does understand and
kind of stick to those which is how
engineering Works in general right you
don't predict everything you just stick
to things that you can predict and I
think that's going to be a powerful
approach so anyway sorry to go back to
being a Doomer and giving you the Doomer
case I just don't see a lot of optimism
for any of these particular reasons I
think the two strongest are maybe we'll
get another winter because progress is
hard to predict and unknown unknowns
right I just don't feel really confident
but logically I also don't see why I
shouldn't feel confident that's where I
stand right now I I will say this for
what it's worth my gut isn't freaking
out right I'm still on some level I'm
still expecting to have like another
nice day another nice day and like today
my cell phone service actually went out
for like the first time in 10 years
randomly Verizon had a nationwide outage
and I was like God damn it put that
phone back I'm busy okay I'm a busy man
let's go let's get the service back even
though I know like hey maybe in 5 years
it's going to permanently go out right
so it's like I should be like mentally
prepared for this but I'm like hell no
get that cell phone service back on
let's go I got to do so on some
level my gut just expects to have normal
days have a good time relax even though
my logical mind is like I don't see how
that's going to happen manic mind trick
question number three have you ever
taken a standardized IQ test and what
was the result I never have I wish I did
to get an official score since I think
IQ is important I'm always talking about
how you know people in certain IQ ranges
ought to do this and that right like
with college so okay an IQ of 130 is top
2% and IQ of 145 is top
0.1% I would guess objectively that my
IQ is 135 to 150 I.E I might be the
smartest person among 100 to 2,000
people I'm not sure it could be off on
that this is just based on my experience
being at the top of my classes like in
high school and college but not like so
crazily at the top that I've like never
heard of anybody better than me at this
stuff like I actually do know plenty of
people better than me at this stuff even
in my high school and college also sat I
guess is a proxy for IQ so when I took
the sat1 in 200 four my score was 1560
out of 1,600 obviously 800 math because
they made the math super easy verbal
only 760 like in retrospect I'm like
come on pass self you couldn't even get
800 verbal like was it really that hard
I probably could have crammed like done
a better job cramming I guess I just
needed like more vocabulary or like more
practice with reading comprehension but
like I I don't see what the issue was
with that test in retrospect I just get
the sense that my present self if I got
to tutor my past self probably could
have bumped the score up a little bit
but I mean I guess 7 60 is not bad I
found a random website that Maps SAT
scores to IQs because I think there is a
pretty strong correlation and it says
that if somebody gets a 1560 then their
IQ is 150 so hell yeah I'll take that
but honestly it's probably lower I think
it's just when you get near 1600 it's
like what are you going to say right
1600 has to map to like a pretty high IQ
so they're like running out of SAT
scores that they could possibly map to a
high IQ so I think I'm benefiting from
that effect how people use their IQ
matters a lot it seems like for me
person personally these particular
skills come easy reducing things down to
a few simple fundamental components and
understanding the range of possible
interactions between small numbers of
components feel like I'm good at that
rationality and epistemology kind of my
forte you know thei stuff really speaks
to
me separating object level arguments
from ad homonyms and other metal level
discussion is like super easy for me
I've been surprised how shockingly hard
it seems to to be for everybody
else explaining things SL putting my
thoughts into
words and speaking in an engaging SL
entertaining way I feel like those
particular areas happen to be like a
convergence of what I'm good at like
regardless of my IQ right so even if
some people have like a somewhat higher
IQ but they might be worse than me at
these particular subskills these
intelligence subskills and then
conversely maybe I have a higher IQ than
somebody else but I kind of hate like
differential equations or whatever right
like that's not my forte within math so
there's definitely wiggle room within
humans with similar IQs I do think that
the topic of AI doom and podcasting
about AI Doom you know it's no surprise
I'm doing this particular podcast right
I'm trying to play to my strengths and
also trying to maximize my impact my raw
mental horsepower isn't super unique for
looking at the human population there's
Millions like me but if I pick the right
thing to use it on if I play to my
strengths maybe I can change the world I
think it plays to my strengths to take
on the mission of raising mainstream
awareness of imminent Extinction from
AGI and building the social
infrastructure for high quality debate
just feels like a good fit and certainly
something that there's a need for anyway
back to the whole IQ topic one reason I
think my IQ is not genius level not 150
plus is because I just have so many
memories of times in my life where I've
just been so dumb like dumb as hell when
I was a single nerd trying to meet
ladies I read various blogs and pickup
artist books and I just accepted a lot
of the advice is probably accurate like
oh yeah it's a big Up Artist book they
know what they're talking about and they
would give like terrible advice like
don't think me wrong there's like some
good nuggets but a lot of terrible
advice where it's like I'm applying the
advice I'm like why am I applying this
advice you know like oh tell a long
story about like how awesome your life
is it's like why am I standing here
telling a long awkward story like this
is bad technique right I eventually
realized after like a million awkward
interactions right and that's just like
one of the tips uh I didn't do too much
neing if you know that luckily I wasn't
like a huge neg
but that is also like a piece of mostly
bad advice so like how smart can I be if
I can't like notice how bad the advice
is I don't know there it puts an upper
bound right I think I'm effectively
smarter now than I have been in the past
just because I keep refining my
heuristics like I know how to double
check things or like prove the value of
things better than I could before I just
kind of like notice what works right
just building up the patterns basically
how every old person says they're smart
right cuz their patterns are so good
everybody makes that claim I like to
think it's true how I ever know all
right so that's my take on my own IQ
manic mind trick question number four
what would you like to play in your
headphones as the world
ends well I couldn't focus on that
because I have a onrack mind I'd just be
like damn it the world is ending how can
I die painlessly damn it the world is
ending how can I die painlessly like IID
just be focused on that I wouldn't
really care what's playing at that point
so yeah manic mind trick question number
five as we move closer to ASI and
capabilities of AI grow more and more
apparently dangerous and uncontrollable
to the general public we might see
outbreaks of mass fear and targeted
violence towards AI leaders in an
attempt to stop an AI Extinction what is
your thought on
this I don't necessarily think it's true
that this is the social Dynamic to
expect even though non- doomers love to
point to us and be like hey why aren't
you guys going crazy we'll fire at you
guys assassinating people and launching
air strikes on data centers today they
love to be like you guys have weird
beliefs so you should be going crazy
right now it's like uh would you
personally go crazy and they're like yes
I would I'm like would you really though
I don't think so I think that you would
still be you and you wouldn't go crazy
I've read that people in various
disasters typically remain orderly and
helpful to one another even though you
might think like oh it's man against man
now but it's like no they do tend to
follow rules the way they're used to
they do tend to respect authority in the
situation so I'm optimistic that raising
the level of fear could help to Simply
push for a solution that's actually
productive it could actually help us get
to internet government regulation in
instead of like everybody going totally
Lawless and crazy I'm not optimistic
that the resulting regulation will be
enough it probably won't be but I'm
optimistic that fearmongering will
productively help us try and finally
manic mind trick question number six
what's your wife's P Doom good question
manic Mind Trick so I just texted her
and her reply was exact
words no answer don't think about it
ever
and I refuse
to okay so for context my wife is a
normie so that's like a a pretty classic
Normie response which is just like look
it's not my thing like I have other
interests okay you're the doomed guy you
figure it out if you need me to cast a
vote on something hit me up but
otherwise like enjoy being a Doomer
right that's like my wife's attitude
which is just like fine you know we
don't literally need everybody to be a
Doomer as long as they're not getting in
the way I think it's
okay all right so that's part one we're
half way through the questions I'll just
do another one of these episodes I think
everybody who wrote a question deserves
a response as part of your Elite first
thousand subscriber status you deserve
that it's just you got to understand my
predicament you know dealing with a
th000 subscribers it's not easy it's not
easy it's a big burden to carry part of
me wants to be like okay 500 of you get
out get out this is limited to 500 the
other part of me is like oh yeah our
mission is to reach a mainstream
audience of millions of viewers so
really we're just getting started so
stay tuned for part two of the Doom
debates subscriber Q&amp;A hopefully coming
in the next few days if you've made it
this far into the Q&amp;A and you've enjoyed
it but you're not a doom debate
subscriber you were just like browsing
some other video and then you saw it in
your sidebar like hey what kind of
questions is this guy going to answer
and then you clicked and you're like oh
this this is pretty interesting look
it's Do or Die okay if you want to come
join me in part two hit the Subscribe
button now otherwise don't bother okay
make your decision do the right thing
the rest see you subscribers come on
let's go